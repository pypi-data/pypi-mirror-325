import os
from azure.identity import DefaultAzureCredential

class LLMConfig:

    def __init__(self, deployment: str = None, api_key: str = None, max_tokens: int = 150, temperature: float = 0.1, endpoint: str = "databricks-dbrx-instruct", use_simple_prompt: bool = False, debug: bool = False,
                llm_provider: str = "databricks", api_version: str = "2024-02-15-preview"):

        """
        Initialize the LLMConfig
        Parameters:
        deployment (str): LLM against which the query is run.
        api_key (str): The api_key used for authenticating with the LLM.
        max_tokens (int): Maximum number of tokens that the model can generate in a single response.
        temperature (float): Parameter that controls the randomness and creativity of the text generated by the LLM.
        endpoint (str): The endpoint of the LLM to connect to.
        debug (bool) OPTIONAL: Set Langchain debug for troubleshooting.
        use_simple_prompt (bool) OPTIONAL: Simple Prompt template for a language model.
        llm_provider (str): Provider of the LLM.
        api_version (str): version of the LLM API that the application will use for making requests.
        """

        self.endpoint = endpoint
        self.deployment = deployment
        self.api_key = api_key
        self.api_version = api_version
        self.use_simple_prompt = use_simple_prompt
        self.debug = debug
        self.llm_provider = llm_provider
        self.max_tokens = max_tokens
        self.temperature = temperature


    def get_azure_ad_token(self):
        # Get the Azure Credential
        credential = DefaultAzureCredential()
        # Set the API type to `azure_ad`
        os.environ["OPENAI_API_TYPE"] = "azure_ad"
        # Set the API_KEY to the token from the Azure credential
        self.aad_token = credential.get_token("https://cognitiveservices.azure.com/.default").token
