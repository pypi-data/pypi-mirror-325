defaults:
  - chem_mrl_schema

model_name: seyonec/SMILES_tokenized_PubChem_shard00_160k # Name of the model to use. Must be either a file path or a HF transformer model name.
smiles_a_column_name: smiles_a
smiles_b_column_name: smiles_b
label_column_name: similarity
embedding_pooling: mean # Pooling layer method applied to the embeddings.
# For details visit: https://sbert.net/docs/package_reference/sentence_transformer/models.html#sentence_transformers.models.Pooling
# Valid options
# - mean
# - mean_sqrt_len_tokens
# - weightedmean
# - lasttoken
loss_func: tanimotosentloss # ChemMRL loss function
# Valid options
# - tanimotosentloss
# - tanimotosimilarityloss
# - cosentloss
# - angleloss
tanimoto_similarity_loss_func: null # Base loss function for tanimoto similarity loss function (only for tanimotosimilarityloss)
# Valid options
# - null
# - mse
# - l1
# - smooth_l1
# - huber
# - bin_cross_entropy
# - kldiv
# - cosine_embedding_loss
eval_similarity_fct: tanimoto # Similarity function to use for evaluation
# Valid options
# - cosine
# - tanimoto
eval_metric: spearman # Metric to use for evaluation
# Valid options
# - spearman
# - pearson
mrl_dimensions:
  [768, 512, 256, 128, 64, 32, 16, 8] # A list of embedding dimensions to be used for the loss function.
  # Each value must be less than equal to the base transformer's hidden dimension.
mrl_dimension_weights:
  [1, 1, 1, 1, 1, 1, 1, 1] # A list of weights to be used for the loss function.
  # The number of dimension weights must match that of the MRL dimensions.
n_dims_per_step:
  -1 # The number of dimensions to use per step. If -1, then all dimensions are used.
  # If > 0, then a random sample of n_dims_per_step dimensions are used per step.
use_2d_matryoshka: false # Use 2D Matryoshka to train over transformer layers in addition to embedding dimensions.
