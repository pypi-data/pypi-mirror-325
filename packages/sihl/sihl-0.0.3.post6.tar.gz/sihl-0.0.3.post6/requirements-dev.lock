# generated by rye
# use `rye lock` or `rye sync` to update this lockfile
#
# last locked with the following flags:
#   pre: false
#   features: []
#   all-features: false
#   with-sources: false
#   generate-hashes: false
#   universal: false

-e file:.
absl-py==2.1.0
    # via tensorboard
aiohappyeyeballs==2.4.4
    # via aiohttp
aiohttp==3.11.11
    # via fsspec
aiosignal==1.3.2
    # via aiohttp
asttokens==3.0.0
    # via stack-data
attrs==24.3.0
    # via aiohttp
bleach==6.2.0
    # via kaggle
certifi==2024.12.14
    # via kaggle
    # via requests
charset-normalizer==3.4.1
    # via requests
coloredlogs==15.0.1
    # via onnxruntime
contourpy==1.3.1
    # via matplotlib
coverage==7.6.10
cycler==0.12.1
    # via matplotlib
decorator==5.1.1
    # via ipython
einops==0.8.0
    # via sihl
executing==2.1.0
    # via stack-data
faster-coco-eval==1.6.5
    # via sihl
filelock==3.16.1
    # via huggingface-hub
    # via torch
    # via triton
flatbuffers==24.12.23
    # via onnxruntime
fonttools==4.55.3
    # via matplotlib
frozenlist==1.5.0
    # via aiohttp
    # via aiosignal
fsspec==2024.12.0
    # via huggingface-hub
    # via lightning
    # via pytorch-lightning
    # via torch
grpcio==1.68.1
    # via tensorboard
huggingface-hub==0.27.0
    # via timm
humanfriendly==10.0
    # via coloredlogs
idna==3.10
    # via requests
    # via yarl
iniconfig==2.0.0
    # via pytest
ipython==8.31.0
jedi==0.19.2
    # via ipython
jinja2==3.1.5
    # via torch
kaggle==1.6.17
kiwisolver==1.4.8
    # via matplotlib
lightning==2.5.0.post0
lightning-utilities==0.11.9
    # via lightning
    # via pytorch-lightning
    # via torchmetrics
markdown==3.7
    # via tensorboard
markdown-it-py==3.0.0
    # via rich
markupsafe==3.0.2
    # via jinja2
    # via werkzeug
matplotlib==3.10.0
    # via pycocotools
    # via sihl
matplotlib-inline==0.1.7
    # via ipython
mdurl==0.1.2
    # via markdown-it-py
ml-dtypes==0.5.0
    # via onnxscript
mpmath==1.3.0
    # via sympy
multidict==6.1.0
    # via aiohttp
    # via yarl
networkx==3.4.2
    # via torch
numpy==2.2.1
    # via contourpy
    # via faster-coco-eval
    # via matplotlib
    # via ml-dtypes
    # via onnx
    # via onnxruntime
    # via onnxscript
    # via pandas
    # via pycocotools
    # via tensorboard
    # via torchmetrics
    # via torchvision
nvidia-cublas-cu12==12.4.5.8
    # via nvidia-cudnn-cu12
    # via nvidia-cusolver-cu12
    # via torch
nvidia-cuda-cupti-cu12==12.4.127
    # via torch
nvidia-cuda-nvrtc-cu12==12.4.127
    # via torch
nvidia-cuda-runtime-cu12==12.4.127
    # via torch
nvidia-cudnn-cu12==9.1.0.70
    # via torch
nvidia-cufft-cu12==11.2.1.3
    # via torch
nvidia-curand-cu12==10.3.5.147
    # via torch
nvidia-cusolver-cu12==11.6.1.9
    # via torch
nvidia-cusparse-cu12==12.3.1.170
    # via nvidia-cusolver-cu12
    # via torch
nvidia-nccl-cu12==2.21.5
    # via torch
nvidia-nvjitlink-cu12==12.4.127
    # via nvidia-cusolver-cu12
    # via nvidia-cusparse-cu12
    # via torch
nvidia-nvtx-cu12==12.4.127
    # via torch
onnx==1.17.0
    # via onnxscript
onnxruntime==1.20.1
onnxscript==0.1.0.dev20241230
packaging==24.2
    # via huggingface-hub
    # via lightning
    # via lightning-utilities
    # via matplotlib
    # via onnxruntime
    # via onnxscript
    # via plotly
    # via pytest
    # via pytorch-lightning
    # via tensorboard
    # via torchmetrics
pandas==2.2.3
    # via faster-coco-eval
parso==0.8.4
    # via jedi
pexpect==4.9.0
    # via ipython
pillow==11.0.0
    # via faster-coco-eval
    # via matplotlib
    # via torchvision
plotly==5.24.1
    # via faster-coco-eval
pluggy==1.5.0
    # via pytest
prompt-toolkit==3.0.48
    # via ipython
propcache==0.2.1
    # via aiohttp
    # via yarl
protobuf==5.29.2
    # via onnx
    # via onnxruntime
    # via tensorboard
ptyprocess==0.7.0
    # via pexpect
pure-eval==0.2.3
    # via stack-data
pycocotools==2.0.8
pygments==2.18.0
    # via ipython
    # via rich
pyinstrument==5.0.0
pyparsing==3.2.0
    # via matplotlib
pytest==8.3.4
python-dateutil==2.9.0.post0
    # via kaggle
    # via matplotlib
    # via pandas
python-slugify==8.0.4
    # via kaggle
pytorch-lightning==2.5.0.post0
    # via lightning
pytz==2024.2
    # via pandas
pyyaml==6.0.2
    # via huggingface-hub
    # via lightning
    # via pytorch-lightning
    # via timm
requests==2.32.3
    # via huggingface-hub
    # via kaggle
rich==13.9.4
safetensors==0.4.5
    # via timm
setuptools==75.6.0
    # via lightning-utilities
    # via tensorboard
    # via torch
six==1.17.0
    # via kaggle
    # via python-dateutil
    # via tensorboard
stack-data==0.6.3
    # via ipython
sympy==1.13.1
    # via onnxruntime
    # via torch
tenacity==9.0.0
    # via plotly
tensorboard==2.18.0
tensorboard-data-server==0.7.2
    # via tensorboard
text-unidecode==1.3
    # via python-slugify
timm==1.0.12
torch==2.5.1
    # via lightning
    # via pytorch-lightning
    # via sihl
    # via timm
    # via torchmetrics
    # via torchvision
torchinfo==1.8.0
torchmetrics==1.6.1
    # via lightning
    # via pytorch-lightning
    # via sihl
torchvision==0.20.1
    # via sihl
    # via timm
tqdm==4.67.1
    # via huggingface-hub
    # via kaggle
    # via lightning
    # via pytorch-lightning
traitlets==5.14.3
    # via ipython
    # via matplotlib-inline
triton==3.1.0
    # via torch
types-pyyaml==6.0.12.20241230
typing-extensions==4.12.2
    # via huggingface-hub
    # via lightning
    # via lightning-utilities
    # via onnxscript
    # via pytorch-lightning
    # via torch
tzdata==2024.2
    # via pandas
urllib3==2.3.0
    # via kaggle
    # via requests
wcwidth==0.2.13
    # via prompt-toolkit
webencodings==0.5.1
    # via bleach
werkzeug==3.1.3
    # via tensorboard
yarl==1.18.3
    # via aiohttp
