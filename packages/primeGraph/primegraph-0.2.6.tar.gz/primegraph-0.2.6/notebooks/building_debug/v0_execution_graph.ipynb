{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../..\"))\n",
    "\n",
    "\n",
    "from primeGraph.buffer.factory import History, Incremental, LastValue\n",
    "from primeGraph.constants import END, START\n",
    "from primeGraph.graph.executable import Graph\n",
    "from primeGraph.models.state import GraphState"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing execution plan conversion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "egraph = Graph()\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def a():\n",
    "    time.sleep(1)\n",
    "    print(\"a \\n\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def b():\n",
    "    time.sleep(1)\n",
    "    print(\"b \\n\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def c():\n",
    "    time.sleep(1)\n",
    "    print(\"c \\n\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def d():\n",
    "    time.sleep(1)\n",
    "    print(\"d \\n\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def e():\n",
    "    time.sleep(1)\n",
    "    print(\"e \\n\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def f():\n",
    "    time.sleep(1)\n",
    "    print(\"f\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def g():\n",
    "    time.sleep(1)\n",
    "    print(\"g \\n\", datetime.now())\n",
    "\n",
    "\n",
    "egraph.add_edge(START, \"a\")\n",
    "egraph.add_edge(\"a\", \"b\")\n",
    "egraph.add_edge(\"b\", \"c\")\n",
    "egraph.add_edge(\"b\", \"d\")\n",
    "egraph.add_edge(\"d\", \"e\")\n",
    "egraph.add_edge(\"c\", \"f\")\n",
    "egraph.add_edge(\"f\", \"g\")\n",
    "egraph.add_edge(\"e\", \"g\")\n",
    "egraph.add_edge(\"g\", END)\n",
    "\n",
    "egraph.compile()\n",
    "egraph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "egraph.execution_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "egraph.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "egraph = Graph()\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def a():\n",
    "    time.sleep(1)\n",
    "    print(\"a\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def b():\n",
    "    time.sleep(1)\n",
    "    print(\"b\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def c():\n",
    "    time.sleep(1)\n",
    "    print(\"c\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def d():\n",
    "    time.sleep(1)\n",
    "    print(\"d\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def e():\n",
    "    time.sleep(1)\n",
    "    print(\"e\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def f():\n",
    "    time.sleep(1)\n",
    "    print(\"f\", datetime.now())\n",
    "\n",
    "\n",
    "@egraph.node()\n",
    "def g():\n",
    "    time.sleep(1)\n",
    "    time.sleep(1)\n",
    "    print(\"g\", datetime.now())\n",
    "\n",
    "\n",
    "egraph.add_edge(START, \"a\")\n",
    "egraph.add_edge(\"a\", \"b\")\n",
    "egraph.add_edge(\"b\", \"c\")\n",
    "egraph.add_edge(\"c\", \"d\")\n",
    "egraph.add_edge(\"d\", \"e\")\n",
    "egraph.add_edge(\"e\", \"f\")\n",
    "egraph.add_edge(\"f\", \"g\")\n",
    "egraph.add_edge(\"g\", END)\n",
    "\n",
    "egraph.compile()\n",
    "egraph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "egraph.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "# Create a test graph with a mix of parallel and sequential paths\n",
    "test_graph = Graph()\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def start_task():\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S.%f')}] Starting workflow \\n\")\n",
    "    time.sleep(1)\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def parallel_task_1():\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S.%f')}] Starting parallel task 1 \\n\")\n",
    "    time.sleep(4)\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S.%f')}] Finished parallel task 1 \\n\")\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def parallel_task_2():\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S.%f')}] Starting parallel task 2 \\n\")\n",
    "    time.sleep(4)\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S.%f')}] Finished parallel task 2 \\n\")\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def final_task():\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S.%f')}] Running final task \\n\")\n",
    "    time.sleep(1)\n",
    "\n",
    "\n",
    "# Create a workflow with parallel execution\n",
    "test_graph.add_edge(START, \"start_task\")\n",
    "test_graph.add_edge(\"start_task\", \"parallel_task_1\")\n",
    "test_graph.add_edge(\"start_task\", \"parallel_task_2\")\n",
    "test_graph.add_edge(\"parallel_task_1\", \"final_task\")\n",
    "test_graph.add_edge(\"parallel_task_2\", \"final_task\")\n",
    "test_graph.add_edge(\"final_task\", END)\n",
    "\n",
    "# Compile and execute\n",
    "test_graph.compile()\n",
    "print(\"\\nExecution Plan:\")\n",
    "rprint(test_graph.execution_plan)\n",
    "print(\"\\nStarting execution:\")\n",
    "start_time = time.time()\n",
    "test_graph.execute()\n",
    "end_time = time.time()\n",
    "print(f\"\\nTotal execution time: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "# Define a state model with different buffer types\n",
    "class TestState(GraphState):\n",
    "    counter: Incremental[int]  # Will accumulate values\n",
    "    metrics: History[Dict[str, float]]  # Will keep history of all updates\n",
    "    current_status: LastValue[str]  # Will only keep last value\n",
    "\n",
    "\n",
    "# Initialize the graph with state\n",
    "state = TestState(counter=0, metrics={}, current_status=\"\")\n",
    "\n",
    "test_graph = Graph(state=state)\n",
    "\n",
    "\n",
    "# Test Incremental Buffer\n",
    "@test_graph.node()\n",
    "def add_to_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"counter\": 5}\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def add_more_to_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"counter\": 3}\n",
    "\n",
    "\n",
    "# Test History Buffer\n",
    "@test_graph.node()\n",
    "def add_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"metrics\": {\"accuracy\": 0.95, \"loss\": 0.1}}\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def update_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"metrics\": {\"loss\": 0.05, \"precision\": 0.88}}\n",
    "\n",
    "\n",
    "# Test LastValue Buffer\n",
    "@test_graph.node()\n",
    "def set_status_running(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"current_status\": \"running\"}\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def set_status_complete(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"current_status\": \"complete\"}\n",
    "\n",
    "\n",
    "# Create the workflow\n",
    "test_graph.add_edge(START, \"add_to_counter\")\n",
    "test_graph.add_edge(\"add_to_counter\", \"add_more_to_counter\")\n",
    "test_graph.add_edge(\"add_more_to_counter\", \"add_metrics\")\n",
    "test_graph.add_edge(\"add_metrics\", \"update_metrics\")\n",
    "test_graph.add_edge(\"update_metrics\", \"set_status_running\")\n",
    "test_graph.add_edge(\"set_status_running\", \"set_status_complete\")\n",
    "test_graph.add_edge(\"set_status_complete\", END)\n",
    "\n",
    "# Compile and execute\n",
    "test_graph.compile()\n",
    "test_graph.execute(timeout=10)\n",
    "\n",
    "# Print final state\n",
    "print(\"\\nFinal State:\")\n",
    "print(f\"Counter: {test_graph.state.counter}\")  # Should be 8 (5 + 3)\n",
    "print(\n",
    "    f\"Metrics History: {test_graph.state.metrics}\"\n",
    ")  # Should contain both metric updates\n",
    "print(f\"Current Status: {test_graph.state.current_status}\")  # Should be \"complete\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from tiny_graph.buffer.factory import History, Incremental, LastValue\n",
    "from tiny_graph.constants import END, START\n",
    "from tiny_graph.graph.executable import Graph\n",
    "from tiny_graph.models.state import GraphState\n",
    "\n",
    "\n",
    "# Define a state model with different buffer types\n",
    "class TestState(GraphState):\n",
    "    counter: Incremental[int]  # Will accumulate values\n",
    "    metrics: History[Dict[str, float]]  # Will keep history of all updates\n",
    "    current_status: LastValue[str]  # Will only keep last value\n",
    "\n",
    "\n",
    "# Initialize the graph with state\n",
    "state = TestState(counter=0, metrics={}, current_status=\"\")\n",
    "\n",
    "test_graph = Graph(state=state)\n",
    "\n",
    "\n",
    "# Define nodes that will run in parallel and update the same state\n",
    "@test_graph.node()\n",
    "def increment_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"counter\": 1}\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def decrement_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"counter\": -1}\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def update_status(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"current_status\": \"in_progress\"}\n",
    "\n",
    "\n",
    "# Create the workflow with parallel execution\n",
    "test_graph.add_edge(START, \"increment_counter\")\n",
    "test_graph.add_edge(START, \"decrement_counter\")\n",
    "test_graph.add_edge(START, \"update_status\")\n",
    "test_graph.add_edge(\"increment_counter\", END)\n",
    "test_graph.add_edge(\"decrement_counter\", END)\n",
    "test_graph.add_edge(\"update_status\", END)\n",
    "\n",
    "# Compile and execute\n",
    "test_graph.compile()\n",
    "test_graph.execute(timeout=10)\n",
    "\n",
    "# Print final state\n",
    "print(\"\\nFinal State:\")\n",
    "print(\n",
    "    f\"Counter: {test_graph.state.counter}\"\n",
    ")  # Should reflect the net effect of increments and decrements\n",
    "print(\n",
    "    f\"Metrics History: {test_graph.state.metrics}\"\n",
    ")  # Should be empty as no metrics are updated\n",
    "print(f\"Current Status: {test_graph.state.current_status}\")  # Should be \"in_progress\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph.execution_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph()\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def escape():\n",
    "    print(\"Starting workflow\")\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def process_data():\n",
    "    print(\"Processing data\")\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def validate():\n",
    "    print(\"Validating results\")\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def aa():\n",
    "    print(\"Validating results\")\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def bb():\n",
    "    print(\"Validating results\")\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def prep():\n",
    "    print(\"Workflow complete\")\n",
    "\n",
    "\n",
    "graph.add_edge(START, \"process_data\")\n",
    "graph.add_edge(\"process_data\", \"validate\")\n",
    "graph.add_edge(\"validate\", \"escape\")\n",
    "graph.add_edge(\"escape\", \"prep\")\n",
    "graph.add_edge(\"validate\", \"aa\")\n",
    "graph.add_edge(\"aa\", \"bb\")\n",
    "graph.add_edge(\"bb\", \"prep\")\n",
    "graph.add_edge(\"prep\", END)\n",
    "\n",
    "graph.compile()\n",
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.execution_plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from rich import print as rprint\n",
    "from tiny_graph.buffer.factory import History, Incremental, LastValue\n",
    "from tiny_graph.graph.executable import Graph\n",
    "from tiny_graph.models.state import GraphState\n",
    "\n",
    "\n",
    "# Define a state model with buffer types\n",
    "class ComplexTestState(GraphState):\n",
    "    counter: Incremental[int]  # Will accumulate values\n",
    "    status: LastValue[str]  # Will only keep last value\n",
    "    metrics: History[Dict[str, float]]  # Will keep history of all updates\n",
    "\n",
    "\n",
    "# Initialize the graph with state\n",
    "state = ComplexTestState(counter=3, status=\"\", metrics={})\n",
    "graph = Graph(state=state)\n",
    "\n",
    "\n",
    "# Define nodes that will run in parallel and update the same state\n",
    "@graph.node()\n",
    "def increment_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"counter\": 2}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def decrement_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"counter\": -1}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def update_status_to_in_progress(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"status\": \"in_progress\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def update_status_to_complete(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"status\": \"complete\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def add_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"metrics\": {\"accuracy\": 0.9, \"loss\": 0.1}}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def update_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"metrics\": {\"loss\": 0.05, \"precision\": 0.85}}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def finalize_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"metrics\": {\"loss\": 0.01, \"precision\": 0.99}}\n",
    "\n",
    "\n",
    "# Create the workflow with multiple levels of execution\n",
    "graph.add_edge(START, \"increment_counter\")\n",
    "graph.add_edge(START, \"decrement_counter\")\n",
    "graph.add_edge(START, \"update_status_to_in_progress\")\n",
    "graph.add_edge(\"increment_counter\", \"add_metrics\")\n",
    "graph.add_edge(\"decrement_counter\", \"add_metrics\")\n",
    "graph.add_edge(\"add_metrics\", \"update_metrics\")\n",
    "graph.add_edge(\"update_metrics\", \"finalize_metrics\")\n",
    "graph.add_edge(\"update_status_to_in_progress\", \"update_status_to_complete\")\n",
    "graph.add_edge(\"update_status_to_complete\", \"finalize_metrics\")\n",
    "graph.add_edge(\"finalize_metrics\", END)\n",
    "\n",
    "# Compile and execute\n",
    "graph.compile()\n",
    "\n",
    "\n",
    "graph.start(timeout=10)\n",
    "\n",
    "rprint(graph.state)\n",
    "\n",
    "# Assert final state\n",
    "assert (\n",
    "    graph.state.counter == 1\n",
    "), \"Counter should reflect net effect of increments and decrements\"\n",
    "assert graph.state.status == \"complete\", \"Status should be 'complete'\"\n",
    "assert len(graph.state.metrics) == 3, \"Metrics should contain three updates\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprint(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from rich import print as rprint\n",
    "from tiny_graph.buffer.factory import History, Incremental, LastValue\n",
    "from tiny_graph.graph.executable import Graph\n",
    "from tiny_graph.models.state import GraphState\n",
    "\n",
    "\n",
    "# Define a state model with buffer types\n",
    "class ComplexTestState(GraphState):\n",
    "    counter: Incremental[int]  # Will accumulate values\n",
    "    status: LastValue[str]  # Will only keep last value\n",
    "    metrics: History[Dict[str, float]]  # Will keep history of all updates\n",
    "\n",
    "\n",
    "# Initialize the graph with state\n",
    "state = ComplexTestState(counter=3, status=\"\", metrics={\"xablau\": 2.0})\n",
    "graph = Graph(state=state)\n",
    "\n",
    "\n",
    "# Define nodes that will run in parallel and update the same state\n",
    "@graph.node()\n",
    "def increment_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"counter\": 2}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def decrement_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"counter\": -1}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def update_status_to_in_progress(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"status\": \"in_progress\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def update_status_to_complete(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"status\": \"complete\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def add_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"metrics\": {\"accuracy\": 0.9, \"loss\": 0.1}}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def update_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"metrics\": {\"loss\": 0.05, \"precision\": 0.85}}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def finalize_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    return {\"metrics\": {\"loss\": 0.01, \"precision\": 0.99}}\n",
    "\n",
    "\n",
    "# Create the workflow with multiple levels of execution\n",
    "graph.add_edge(START, \"increment_counter\")\n",
    "graph.add_edge(START, \"decrement_counter\")\n",
    "graph.add_edge(START, \"update_status_to_in_progress\")\n",
    "graph.add_edge(\"increment_counter\", \"add_metrics\")\n",
    "graph.add_edge(\"decrement_counter\", \"add_metrics\")\n",
    "graph.add_edge(\"add_metrics\", \"update_metrics\")\n",
    "graph.add_edge(\"update_metrics\", \"finalize_metrics\")\n",
    "graph.add_edge(\"update_status_to_in_progress\", \"update_status_to_complete\")\n",
    "graph.add_edge(\"update_status_to_complete\", \"finalize_metrics\")\n",
    "graph.add_edge(\"finalize_metrics\", END)\n",
    "\n",
    "# Compile and execute\n",
    "graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.buffers[\"counter\"].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.buffers[\"metrics\"].value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph = Graph()\n",
    "\n",
    "\n",
    "# Define some example actions\n",
    "@simple_graph.node(interrupt=\"before\")\n",
    "def escape():\n",
    "    print(\"Starting workflow\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def process_data():\n",
    "    print(\"Processing data\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def validate():\n",
    "    print(\"Validating results\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def aa():\n",
    "    print(\"Validating results\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def bb():\n",
    "    print(\"Validating results\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def dd():\n",
    "    print(\"Validating results\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def cc():\n",
    "    print(\"Validating results\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def hh():\n",
    "    print(\"Validating results\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def prep():\n",
    "    print(\"Workflow complete\")\n",
    "\n",
    "\n",
    "# Add edges to create workflow\n",
    "simple_graph.add_edge(START, \"process_data\")\n",
    "simple_graph.add_edge(\"process_data\", \"validate\")\n",
    "simple_graph.add_edge(\"validate\", \"escape\")\n",
    "simple_graph.add_edge(\"escape\", \"dd\")\n",
    "simple_graph.add_edge(\"escape\", \"cc\")\n",
    "simple_graph.add_edge(\"cc\", \"hh\")\n",
    "simple_graph.add_edge(\"dd\", \"hh\")\n",
    "simple_graph.add_edge(\"hh\", \"prep\")\n",
    "simple_graph.add_edge(\"validate\", \"aa\")\n",
    "simple_graph.add_edge(\"aa\", \"bb\")\n",
    "simple_graph.add_edge(\"bb\", \"prep\")\n",
    "simple_graph.add_edge(\"prep\", END)\n",
    "\n",
    "simple_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph.execution_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "rprint(simple_graph.execution_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprint(simple_graph._convert_execution_plan())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_execution_plan(plan, metadata):\n",
    "    def slice_list(lst, meta):\n",
    "        result = []\n",
    "        for item in lst:\n",
    "            if isinstance(item, list):\n",
    "                # Recursively slice nested lists\n",
    "                sliced_item = slice_list(item, meta)\n",
    "                if sliced_item:\n",
    "                    result.append(sliced_item)\n",
    "            else:\n",
    "                # Check metadata for slicing\n",
    "                if meta.get(item) == \"before\":\n",
    "                    break\n",
    "                result.append(item)\n",
    "                if meta.get(item) == \"after\":\n",
    "                    break\n",
    "        return result\n",
    "\n",
    "    return slice_list(plan, metadata)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "execution_plan = [\n",
    "    \"process_data\",\n",
    "    \"validate\",\n",
    "    [[\"escape\", [\"dd\", \"cc\"], \"hh\"], [\"aa\", \"bb\"]],\n",
    "    \"prep\",\n",
    "]\n",
    "metadata = {\n",
    "    # 'process_data': 'after',\n",
    "    # 'validate': 'before',\n",
    "    # 'escape': 'after',\n",
    "    \"dd\": \"before\",\n",
    "    # 'cc': 'after',\n",
    "    # 'hh': 'before',\n",
    "    # 'aa': 'after',\n",
    "    # 'bb': 'before',\n",
    "    # 'prep': 'after'\n",
    "}\n",
    "\n",
    "sliced_plan = slice_execution_plan(execution_plan, metadata)\n",
    "print(sliced_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_plan[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem here is that in the case of update_status_to_complete,\n",
    "# it's not checking if the next node is a convergence point\n",
    "\n",
    "# it needs to have a function that will check if the next node\n",
    "# connector. find_convergence_point is not doing enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing interruption\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from tiny_graph.buffer.factory import History, Incremental, LastValue\n",
    "from tiny_graph.models.state import GraphState\n",
    "\n",
    "\n",
    "# Define a state model with different buffer types\n",
    "class TestState(GraphState):\n",
    "    counter: Incremental[int]  # Will accumulate values\n",
    "    metrics: History[Dict[str, float]]  # Will keep history of all updates\n",
    "    current_status: LastValue[str]  # Will only keep last value\n",
    "\n",
    "\n",
    "# Initialize the graph with state\n",
    "state = TestState(counter=0, metrics={}, current_status=\"\")\n",
    "\n",
    "test_graph = Graph(state=state)\n",
    "\n",
    "\n",
    "# Test Incremental Buffer\n",
    "@test_graph.node()\n",
    "def add_to_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"add_to_counter\")\n",
    "    return {\"counter\": 5}\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def add_more_to_counter(state):\n",
    "    print(\"add_more_to_counter\")\n",
    "    time.sleep(0.5)\n",
    "    return {\"counter\": 3}\n",
    "\n",
    "\n",
    "# Test History Buffer\n",
    "@test_graph.node(interrupt=\"before\")\n",
    "def add_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"add_metrics\")\n",
    "    return {\"metrics\": {\"accuracy\": 0.95, \"loss\": 0.1}}\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def update_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"update_metrics\")\n",
    "    return {\"metrics\": {\"loss\": 0.05, \"precision\": 0.88}}\n",
    "\n",
    "\n",
    "# Test LastValue Buffer\n",
    "@test_graph.node(interrupt=\"after\")\n",
    "def set_status_running(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"set_status_running\")\n",
    "    return {\"current_status\": \"running\"}\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def set_status_complete(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"set_status_complete\")\n",
    "    return {\"current_status\": \"complete\"}\n",
    "\n",
    "\n",
    "# Create the workflow\n",
    "test_graph.add_edge(START, \"add_to_counter\")\n",
    "test_graph.add_edge(\"add_to_counter\", \"add_more_to_counter\")\n",
    "test_graph.add_edge(\"add_more_to_counter\", \"add_metrics\")\n",
    "test_graph.add_edge(\"add_metrics\", \"update_metrics\")\n",
    "test_graph.add_edge(\"update_metrics\", \"set_status_running\")\n",
    "test_graph.add_edge(\"set_status_running\", \"set_status_complete\")\n",
    "test_graph.add_edge(\"set_status_complete\", END)\n",
    "\n",
    "# Compile and execute\n",
    "test_graph.compile()\n",
    "test_graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph.executed_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "test_graph._convert_execution_plan()\n",
    "rprint(test_graph.execution_plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = escape\n",
    "\n",
    "x.__metadata__[\"interrupt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph = Graph()\n",
    "\n",
    "\n",
    "# Define some example actions\n",
    "@simple_graph.node(interrupt=\"before\")\n",
    "def escape():\n",
    "    time.sleep(0.5)\n",
    "    print(\"escape\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def process_data():\n",
    "    time.sleep(1.5)\n",
    "    print(\"process_data\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def validate():\n",
    "    time.sleep(0.5)\n",
    "    print(\"validate\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def aa():\n",
    "    time.sleep(1.5)\n",
    "    print(\"aa\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def bb():\n",
    "    time.sleep(0.5)\n",
    "    print(\"bb\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def dd():\n",
    "    time.sleep(1.5)\n",
    "    print(\"dd\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def cc():\n",
    "    time.sleep(1.5)\n",
    "    print(\"cc\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def hh():\n",
    "    time.sleep(0.5)\n",
    "    print(\"hh\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def prep():\n",
    "    time.sleep(0.5)\n",
    "    print(\"prep\")\n",
    "\n",
    "\n",
    "# Add edges to create workflow\n",
    "simple_graph.add_edge(START, \"process_data\")\n",
    "simple_graph.add_edge(\"process_data\", \"validate\")\n",
    "simple_graph.add_edge(\"validate\", \"escape\")\n",
    "simple_graph.add_edge(\"escape\", \"dd\")\n",
    "simple_graph.add_edge(\"escape\", \"cc\")\n",
    "simple_graph.add_edge(\"cc\", \"hh\")\n",
    "simple_graph.add_edge(\"dd\", \"hh\")\n",
    "simple_graph.add_edge(\"hh\", \"prep\")\n",
    "simple_graph.add_edge(\"validate\", \"aa\")\n",
    "simple_graph.add_edge(\"aa\", \"bb\")\n",
    "simple_graph.add_edge(\"bb\", \"prep\")\n",
    "simple_graph.add_edge(\"prep\", END)\n",
    "\n",
    "simple_graph.compile()\n",
    "\n",
    "simple_graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "rprint(simple_graph.execution_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "rprint(simple_graph.detailed_execution_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "simple_graph._convert_execution_plan()\n",
    "rprint(simple_graph.execution_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Union\n",
    "\n",
    "from rich import print as rprint\n",
    "from tiny_graph.graph.executable import ExecutableNode\n",
    "\n",
    "\n",
    "def add_item_to_obj_store(obj_store: Union[List, Tuple], item):\n",
    "    if isinstance(obj_store, list):\n",
    "        obj_store.append(item)\n",
    "        return obj_store  # Return the modified list\n",
    "    elif isinstance(obj_store, tuple):\n",
    "        return obj_store + (item,)  # Already returns the new tuple\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported object store type: {type(obj_store)}\")\n",
    "\n",
    "\n",
    "def extract_tasks_from_node(node, tasks=[]):\n",
    "    \"\"\"\n",
    "    Extracts tasks from a node, including nested nodes\n",
    "    returns lists for sequential execution and tuples for parallel execution\n",
    "    \"\"\"\n",
    "    tasks = [] if node.execution_type == \"sequential\" else tuple()\n",
    "    for task in node.task_list:\n",
    "        if isinstance(task, ExecutableNode):\n",
    "            if task.execution_type == \"sequential\":\n",
    "                tasks = add_item_to_obj_store(tasks, extract_tasks_from_node(task, []))\n",
    "            else:\n",
    "                tasks = add_item_to_obj_store(\n",
    "                    tasks, extract_tasks_from_node(task, tuple())\n",
    "                )\n",
    "        else:\n",
    "            tasks = add_item_to_obj_store(tasks, task)\n",
    "\n",
    "    return tasks\n",
    "\n",
    "\n",
    "rprint(extract_tasks_from_node(simple_graph.execution_plan[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph.resume()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from rich import print as rprint\n",
    "from tiny_graph.buffer.factory import History, Incremental, LastValue\n",
    "from tiny_graph.graph.executable import Graph\n",
    "from tiny_graph.models.state import GraphState\n",
    "\n",
    "\n",
    "# Define a state model with buffer types\n",
    "class ComplexTestState(GraphState):\n",
    "    counter: Incremental[int]  # Will accumulate values\n",
    "    status: LastValue[str]  # Will only keep last value\n",
    "    metrics: History[Dict[str, float]]  # Will keep history of all updates\n",
    "\n",
    "\n",
    "# Initialize the graph with state\n",
    "state = ComplexTestState(counter=0, status=\"\", metrics={})\n",
    "graph = Graph(state=state)\n",
    "\n",
    "\n",
    "# Define nodes that will run in parallel and update the same state\n",
    "@graph.node()\n",
    "def increment_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"increment_counter\")\n",
    "    return {\"counter\": 2}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def decrement_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"decrement_counter\")\n",
    "    return {\"counter\": -1}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def update_status_to_in_progress(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"update_status_to_in_progress\")\n",
    "    return {\"status\": \"in_progress\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def update_status_to_complete(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"update_status_to_complete\")\n",
    "    return {\"status\": \"complete\"}\n",
    "\n",
    "\n",
    "@graph.node(interrupt=\"after\")\n",
    "def add_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"add_metrics\")\n",
    "    return {\"metrics\": {\"accuracy\": 0.9, \"loss\": 0.1}}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def update_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"update_metrics\")\n",
    "    return {\"metrics\": {\"loss\": 0.05, \"precision\": 0.85}}\n",
    "\n",
    "\n",
    "@graph.node(interrupt=\"before\")\n",
    "def finalize_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"finalize_metrics\")\n",
    "    return {\"metrics\": {\"loss\": 0.01, \"precision\": 0.99}}\n",
    "\n",
    "\n",
    "# Create the workflow with multiple levels of execution\n",
    "graph.add_edge(START, \"increment_counter\")\n",
    "graph.add_edge(START, \"decrement_counter\")\n",
    "graph.add_edge(START, \"update_status_to_in_progress\")\n",
    "graph.add_edge(\"increment_counter\", \"add_metrics\")\n",
    "graph.add_edge(\"decrement_counter\", \"add_metrics\")\n",
    "graph.add_edge(\"add_metrics\", \"update_metrics\")\n",
    "graph.add_edge(\"update_metrics\", \"finalize_metrics\")\n",
    "graph.add_edge(\"update_status_to_in_progress\", \"update_status_to_complete\")\n",
    "graph.add_edge(\"update_status_to_complete\", \"finalize_metrics\")\n",
    "graph.add_edge(\"finalize_metrics\", END)\n",
    "\n",
    "# Compile and execute\n",
    "graph.compile()\n",
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "rprint(graph.execution_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "graph._convert_execution_plan()\n",
    "rprint(graph.execution_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tiny_graph.buffer.factory import History\n",
    "from tiny_graph.models.state import GraphState\n",
    "\n",
    "\n",
    "class StateForTestWithHistory(GraphState):\n",
    "    execution_order: History[str]\n",
    "\n",
    "\n",
    "state = StateForTestWithHistory(execution_order=[])\n",
    "graph = Graph(state=state)\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def task1(state):\n",
    "    return {\"execution_order\": \"task1\"}\n",
    "\n",
    "\n",
    "@graph.node(interrupt=\"after\")\n",
    "def task2(state):\n",
    "    return {\"execution_order\": \"task2\"}\n",
    "\n",
    "\n",
    "@graph.node(interrupt=\"before\")\n",
    "def task3(state):\n",
    "    return {\"execution_order\": \"task3\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def task4(state):\n",
    "    return {\"execution_order\": \"task4\"}\n",
    "\n",
    "\n",
    "graph.add_edge(START, \"task1\")\n",
    "graph.add_edge(\"task1\", \"task2\")\n",
    "graph.add_edge(\"task2\", \"task3\")\n",
    "graph.add_edge(\"task3\", \"task4\")\n",
    "graph.add_edge(\"task4\", END)\n",
    "graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[edge.id for edge in graph.edges if edge.end_node == \"__start__\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.detailed_execution_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Async Execution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1 (testing non-async using execute_async)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from tiny_graph.buffer.factory import History, Incremental, LastValue\n",
    "from tiny_graph.models.state import GraphState\n",
    "\n",
    "\n",
    "# Define a state model with different buffer types\n",
    "class TestState(GraphState):\n",
    "    counter: Incremental[int]  # Will accumulate values\n",
    "    metrics: History[Dict[str, float]]  # Will keep history of all updates\n",
    "    current_status: LastValue[str]  # Will only keep last value\n",
    "\n",
    "\n",
    "# Initialize the graph with state\n",
    "state = TestState(counter=0, metrics=[], current_status=\"\")\n",
    "\n",
    "test_graph = Graph(state=state)\n",
    "\n",
    "\n",
    "# Test Incremental Buffer\n",
    "@test_graph.node()\n",
    "def add_to_counter(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"add_to_counter\")\n",
    "    return {\"counter\": 5}\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def add_more_to_counter(state):\n",
    "    print(\"add_more_to_counter\")\n",
    "    time.sleep(0.5)\n",
    "    return {\"counter\": 3}\n",
    "\n",
    "\n",
    "# Test History Buffer\n",
    "@test_graph.node(interrupt=\"before\")\n",
    "def add_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"add_metrics\")\n",
    "    return {\"metrics\": {\"accuracy\": 0.95, \"loss\": 0.1}}\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def update_metrics(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"update_metrics\")\n",
    "    return {\"metrics\": {\"loss\": 0.05, \"precision\": 0.88}}\n",
    "\n",
    "\n",
    "# Test LastValue Buffer\n",
    "@test_graph.node(interrupt=\"after\")\n",
    "def set_status_running(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"set_status_running\")\n",
    "    return {\"current_status\": \"running\"}\n",
    "\n",
    "\n",
    "@test_graph.node()\n",
    "def set_status_complete(state):\n",
    "    time.sleep(0.5)\n",
    "    print(\"set_status_complete\")\n",
    "    return {\"current_status\": \"complete\"}\n",
    "\n",
    "\n",
    "# Create the workflow\n",
    "test_graph.add_edge(START, \"add_to_counter\")\n",
    "test_graph.add_edge(\"add_to_counter\", \"add_more_to_counter\")\n",
    "test_graph.add_edge(\"add_more_to_counter\", \"add_metrics\")\n",
    "test_graph.add_edge(\"add_metrics\", \"update_metrics\")\n",
    "test_graph.add_edge(\"update_metrics\", \"set_status_running\")\n",
    "test_graph.add_edge(\"set_status_running\", \"set_status_complete\")\n",
    "test_graph.add_edge(\"set_status_complete\", END)\n",
    "\n",
    "# Compile and execute\n",
    "test_graph.compile()\n",
    "test_graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await test_graph.execute_async()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph.executed_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "test_graph._convert_execution_plan()\n",
    "rprint(test_graph.execution_plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph = Graph()\n",
    "\n",
    "\n",
    "# Define some example actions\n",
    "@simple_graph.node()\n",
    "def step_1():\n",
    "    time.sleep(1)\n",
    "    print(\"start\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def step_A():\n",
    "    time.sleep(2)\n",
    "    print(\"step_A\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def step_B():\n",
    "    time.sleep(2)\n",
    "    print(\"step_B\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "def step_2():\n",
    "    time.sleep(1)\n",
    "    print(\"step_2\")\n",
    "\n",
    "\n",
    "# Add edges to create workflow\n",
    "simple_graph.add_edge(START, \"step_1\")\n",
    "simple_graph.add_edge(\"step_1\", \"step_A\")\n",
    "simple_graph.add_edge(\"step_1\", \"step_B\")\n",
    "simple_graph.add_edge(\"step_A\", \"step_2\")\n",
    "simple_graph.add_edge(\"step_B\", \"step_2\")\n",
    "simple_graph.add_edge(\"step_2\", END)\n",
    "\n",
    "simple_graph.compile()\n",
    "\n",
    "simple_graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await simple_graph.execute_async()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_graph.execution_plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "simple_graph = Graph()\n",
    "\n",
    "\n",
    "# Define some example actions\n",
    "@simple_graph.node()\n",
    "async def step_1():\n",
    "    await asyncio.sleep(1)\n",
    "    print(\"start\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "async def step_A():\n",
    "    await asyncio.sleep(2)\n",
    "    print(\"step_A\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "async def step_B():\n",
    "    await asyncio.sleep(2)\n",
    "    print(\"step_B\")\n",
    "\n",
    "\n",
    "@simple_graph.node()\n",
    "async def step_2():\n",
    "    await asyncio.sleep(1)\n",
    "    print(\"step_2\")\n",
    "\n",
    "\n",
    "# Add edges to create workflow\n",
    "simple_graph.add_edge(START, \"step_1\")\n",
    "simple_graph.add_edge(\"step_1\", \"step_A\")\n",
    "simple_graph.add_edge(\"step_1\", \"step_B\")\n",
    "simple_graph.add_edge(\"step_A\", \"step_2\")\n",
    "simple_graph.add_edge(\"step_B\", \"step_2\")\n",
    "simple_graph.add_edge(\"step_2\", END)\n",
    "\n",
    "simple_graph.compile()\n",
    "\n",
    "simple_graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await simple_graph.execute_async()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tiny_graph.buffer.factory import History\n",
    "from tiny_graph.models.state import GraphState\n",
    "\n",
    "\n",
    "class StateForTestWithHistory(GraphState):\n",
    "    execution_order: History[str]\n",
    "\n",
    "\n",
    "state = StateForTestWithHistory(execution_order=[])\n",
    "graph = Graph(state=state)\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "async def task1(state):\n",
    "    print(\"task1\")\n",
    "    return {\"execution_order\": \"task1\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "async def task2(state):\n",
    "    print(\"task2\")\n",
    "    return {\"execution_order\": \"task2\"}\n",
    "\n",
    "\n",
    "@graph.node(interrupt=\"before\")\n",
    "async def task3(state):\n",
    "    print(\"task3\")\n",
    "    return {\"execution_order\": \"task3\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "async def task4(state):\n",
    "    print(\"task4\")\n",
    "    return {\"execution_order\": \"task4\"}\n",
    "\n",
    "\n",
    "# Create parallel paths\n",
    "graph.add_edge(START, \"task1\")\n",
    "graph.add_edge(\"task1\", \"task2\")\n",
    "graph.add_edge(\"task1\", \"task3\")\n",
    "graph.add_edge(\"task2\", \"task4\")\n",
    "graph.add_edge(\"task3\", \"task4\")\n",
    "graph.add_edge(\"task4\", END)\n",
    "graph.compile()\n",
    "\n",
    "# First execution should execute task1 and task3, but pause before task2\n",
    "# await graph.start_async()\n",
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await graph.resume_async()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await graph.resume_async()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.state.execution_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tiny_graph.buffer.factory import History, Incremental, LastValue\n",
    "from tiny_graph.models.state import GraphState\n",
    "\n",
    "\n",
    "class StateForTestWithHistory(GraphState):\n",
    "    execution_order: History[str]\n",
    "    counter: Incremental[int]\n",
    "\n",
    "\n",
    "StateForTestWithHistory(execution_order=[\"a\", 2], counter=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "\n",
    "class ComplexTestState(GraphState):\n",
    "    counter: Incremental[int]  # Will accumulate values\n",
    "    status: LastValue[str]  # Will only keep last value\n",
    "    metrics: History[Dict[str, float]]  # Will keep history of all updates\n",
    "\n",
    "\n",
    "ComplexTestState(counter=0, status=\"\", metrics=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tiny_graph.checkpoint.local_storage import LocalStorage\n",
    "\n",
    "\n",
    "class SimpleGraphState(GraphState):\n",
    "    messages: History[str]\n",
    "\n",
    "\n",
    "# Create state instance\n",
    "state = SimpleGraphState(messages=[])\n",
    "\n",
    "# Update graph with state\n",
    "storage = LocalStorage()\n",
    "graph1 = Graph(state=state, checkpoint_storage=storage)\n",
    "\n",
    "\n",
    "@graph1.node()\n",
    "def add_hello(state: GraphState):\n",
    "    return {\"messages\": \"Hello\"}\n",
    "\n",
    "\n",
    "@graph1.node()\n",
    "def add_world(state: GraphState):\n",
    "    return {\"messages\": \"World\"}\n",
    "\n",
    "\n",
    "@graph1.node()\n",
    "def add_exclamation(state: GraphState):\n",
    "    return {\"messages\": \"!\"}\n",
    "\n",
    "\n",
    "# Add edges\n",
    "graph1.add_edge(START, \"add_hello\")\n",
    "graph1.add_edge(\"add_hello\", \"add_world\")\n",
    "graph1.add_edge(\"add_world\", \"add_exclamation\")\n",
    "graph1.add_edge(\"add_exclamation\", END)\n",
    "\n",
    "# Add nodes and edges...\n",
    "graph1.compile()\n",
    "graph1.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await graph1.start_async()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage._storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Subgraph Execution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_graph = Graph()\n",
    "\n",
    "\n",
    "@main_graph.node()\n",
    "def start_process():\n",
    "    print(\"Starting main process\")\n",
    "\n",
    "\n",
    "@main_graph.node()\n",
    "def end_process():\n",
    "    print(\"Ending main process\")\n",
    "\n",
    "\n",
    "# Create subgraph\n",
    "sub_graph = Graph()\n",
    "\n",
    "\n",
    "@sub_graph.node()\n",
    "def sub_task1():\n",
    "    print(\"Subtask 1\")\n",
    "\n",
    "\n",
    "@sub_graph.node()\n",
    "def sub_task2():\n",
    "    print(\"Subtask 2\")\n",
    "\n",
    "\n",
    "# Add edges to subgraph\n",
    "sub_graph.add_edge(START, \"sub_task1\")\n",
    "sub_graph.add_edge(\"sub_task1\", \"sub_task2\")\n",
    "sub_graph.add_edge(\"sub_task2\", END)\n",
    "\n",
    "\n",
    "# Add subgraph as a node to main graph\n",
    "@main_graph.subgraph(name=\"processing\")\n",
    "def processing_subgraph():\n",
    "    return sub_graph\n",
    "\n",
    "\n",
    "# Add edges to main graph including the subgraph\n",
    "main_graph.add_edge(START, \"start_process\")\n",
    "main_graph.add_edge(\"start_process\", \"processing\")  # Connect to subgraph\n",
    "main_graph.add_edge(\"processing\", \"end_process\")  # Connect from subgraph\n",
    "main_graph.add_edge(\"end_process\", END)\n",
    "\n",
    "# Compile and visualize\n",
    "main_graph.compile()\n",
    "main_graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_graph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmain_graph.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubgraphState(GraphState):\n",
    "    execution_order: History[str]\n",
    "    counter: Incremental[int]\n",
    "    status: LastValue[str]\n",
    "\n",
    "\n",
    "state = SubgraphState(execution_order=[], counter=0, status=\"\")\n",
    "main_graph = Graph(state=state)\n",
    "\n",
    "\n",
    "# Create a subgraph\n",
    "@main_graph.subgraph()\n",
    "def processing_subgraph():\n",
    "    subgraph = Graph(state=state)\n",
    "\n",
    "    @subgraph.node()\n",
    "    def process_a(state):\n",
    "        return {\"execution_order\": \"process_a\", \"counter\": 1}\n",
    "\n",
    "    @subgraph.node()\n",
    "    def process_b(state):\n",
    "        return {\"execution_order\": \"process_b\", \"counter\": 2}\n",
    "\n",
    "    subgraph.add_edge(START, \"process_a\")\n",
    "    subgraph.add_edge(\"process_a\", \"process_b\")\n",
    "    subgraph.add_edge(\"process_b\", END)\n",
    "\n",
    "    return subgraph\n",
    "\n",
    "\n",
    "# Main graph nodes\n",
    "@main_graph.node()\n",
    "def start_task(state):\n",
    "    return {\"execution_order\": \"start_task\", \"status\": \"started\"}\n",
    "\n",
    "\n",
    "@main_graph.node()\n",
    "def end_task(state):\n",
    "    return {\"execution_order\": \"end_task\", \"status\": \"completed\"}\n",
    "\n",
    "\n",
    "# Connect main graph\n",
    "main_graph.add_edge(START, \"start_task\")\n",
    "main_graph.add_edge(\"start_task\", \"processing_subgraph\")\n",
    "main_graph.add_edge(\"processing_subgraph\", \"end_task\")\n",
    "main_graph.add_edge(\"end_task\", END)\n",
    "\n",
    "main_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_graph.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubgraphState(GraphState):\n",
    "    execution_order: History[str]\n",
    "    counter: Incremental[int]\n",
    "    status: LastValue[str]\n",
    "\n",
    "\n",
    "state = SubgraphState(execution_order=[], counter=0, status=\"\")\n",
    "main_graph = Graph(state=state)\n",
    "\n",
    "\n",
    "def nested_subgraph():\n",
    "    nested = Graph(state=state)\n",
    "\n",
    "    @nested.node()\n",
    "    def nested_task(state):\n",
    "        return {\"execution_order\": \"nested_task\", \"counter\": 1}\n",
    "\n",
    "    @nested.node()\n",
    "    def nested_task_2(state):\n",
    "        return {\"execution_order\": \"nested_task_2\", \"counter\": 2}\n",
    "\n",
    "    nested.add_edge(START, \"nested_task\")\n",
    "    nested.add_edge(\"nested_task\", \"nested_task_2\")\n",
    "    nested.add_edge(\"nested_task_2\", END)\n",
    "    return nested\n",
    "\n",
    "\n",
    "# Create parent subgraph containing nested subgraph\n",
    "@main_graph.subgraph()\n",
    "def parent_subgraph():\n",
    "    parent = Graph(state=state)\n",
    "\n",
    "    @parent.node()\n",
    "    def parent_task(state):\n",
    "        return {\"execution_order\": \"parent_task\", \"counter\": 2}\n",
    "\n",
    "    @parent.subgraph()\n",
    "    def inner_nested():\n",
    "        return nested_subgraph()\n",
    "\n",
    "    parent.add_edge(START, \"parent_task\")\n",
    "    parent.add_edge(\"parent_task\", \"inner_nested\")\n",
    "    parent.add_edge(\"inner_nested\", END)\n",
    "    return parent\n",
    "\n",
    "\n",
    "# Main graph setup\n",
    "@main_graph.node()\n",
    "def main_task(state):\n",
    "    return {\"execution_order\": \"main_task\", \"status\": \"running\"}\n",
    "\n",
    "\n",
    "main_graph.add_edge(START, \"main_task\")\n",
    "main_graph.add_edge(\"main_task\", \"parent_subgraph\")\n",
    "main_graph.add_edge(\"parent_subgraph\", END)\n",
    "\n",
    "main_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_graph.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_graph.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Repeated Nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph()\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def node_a():\n",
    "    print(\"Node A\")\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def node_b():\n",
    "    print(\"Node B\\n\")\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def node_c():\n",
    "    print(\"Node C\")\n",
    "\n",
    "\n",
    "# Add a repeat edge that runs node_b 3 times sequentially\n",
    "graph.add_edge(START, \"node_a\")\n",
    "graph.add_repeating_edge(\"node_a\", \"node_b\", \"node_c\", repeat=3, parallel=False)\n",
    "graph.add_edge(\"node_c\", END)\n",
    "\n",
    "# Or run in parallel\n",
    "# graph.add_repeat_edge(\"node_a\", \"node_b\", \"node_c\", repeat=3, parallel=True)\n",
    "\n",
    "graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.executed_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.detailed_execution_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2 (async)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateWithHistory(GraphState):\n",
    "    execution_order: History[str]\n",
    "    execution_times: History[float]\n",
    "    counter: Incremental[int]\n",
    "\n",
    "\n",
    "state = StateWithHistory(execution_order=[], execution_times=[], counter=0)\n",
    "graph = Graph(state=state)\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "async def start_task(state):\n",
    "    return {}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "async def cpu_intensive_task(state):\n",
    "    # Simulate CPU-intensive work\n",
    "    await asyncio.sleep(0.1)\n",
    "    print(\"cpu_intensive_task_parallel\")\n",
    "    result = 0\n",
    "    for _ in range(1000000):\n",
    "        result += 1\n",
    "    current_time = time.time()\n",
    "    return {\n",
    "        \"execution_order\": f\"task_{len(state.execution_order)}\",\n",
    "        \"execution_times\": current_time,\n",
    "        \"counter\": 1,\n",
    "    }\n",
    "\n",
    "\n",
    "# Create parallel execution with many repetitions\n",
    "graph.add_edge(START, \"start_task\")\n",
    "graph.add_repeating_edge(\n",
    "    \"start_task\", \"cpu_intensive_task\", END, repeat=10, parallel=True\n",
    ")\n",
    "graph.compile()\n",
    "\n",
    "start_time = time.time()\n",
    "await graph.start_async()\n",
    "parallel_time = time.time() - start_time\n",
    "print(f\"Parallel execution time: {parallel_time}\")\n",
    "\n",
    "# Now test sequential execution\n",
    "graph2 = Graph(\n",
    "    state=StateWithHistory(execution_order=[], execution_times=[], counter=0)\n",
    ")\n",
    "\n",
    "\n",
    "@graph2.node()\n",
    "async def start_task(state):\n",
    "    return {}\n",
    "\n",
    "\n",
    "@graph2.node()\n",
    "async def cpu_intensive_task(state):\n",
    "    # Same task as above\n",
    "    await asyncio.sleep(0.1)\n",
    "    print(\"cpu_intensive_task_sequential\")\n",
    "    result = 0\n",
    "    for _ in range(1000000):\n",
    "        result += 1\n",
    "    current_time = time.time()\n",
    "    return {\n",
    "        \"execution_order\": f\"task_{len(state.execution_order)}\",\n",
    "        \"execution_times\": current_time,\n",
    "        \"counter\": 1,\n",
    "    }\n",
    "\n",
    "\n",
    "graph2.add_edge(START, \"start_task\")\n",
    "graph2.add_repeating_edge(\n",
    "    \"start_task\", \"cpu_intensive_task\", END, repeat=10, parallel=False\n",
    ")\n",
    "graph2.compile()\n",
    "\n",
    "start_time = time.time()\n",
    "await graph2.start_async()\n",
    "sequential_time = time.time() - start_time\n",
    "\n",
    "# Parallel execution should be significantly faster\n",
    "assert parallel_time < sequential_time * 0.7  # At least 30% faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_time, sequential_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "rprint(graph.execution_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprint(graph.detailed_execution_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Router Nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from primeGraph.checkpoint.local_storage import LocalStorage\n",
    "\n",
    "\n",
    "# Example usage\n",
    "class TestState(GraphState):\n",
    "    result: LastValue[dict]  # Store the result from routes\n",
    "    execution_order: History[str]  # Track execution order\n",
    "\n",
    "\n",
    "storage = LocalStorage()\n",
    "graph = Graph(\n",
    "    state=TestState(result={}, execution_order=[]), checkpoint_storage=storage\n",
    ")\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def process_data(state):\n",
    "    print(\"Executing process_data\")\n",
    "    # Router node that returns a node name\n",
    "    if True:\n",
    "        return \"route_a\"\n",
    "    return \"route_b\"\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_a(state):\n",
    "    print(\"Executing route_a\")\n",
    "    return {\"result\": {\"result\": \"from route A\"}, \"execution_order\": \"route_a\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_b(state):\n",
    "    print(\"Executing route_b\")\n",
    "    return {\"result\": {\"result\": \"from route B\"}, \"execution_order\": \"route_b\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_a2(state):\n",
    "    print(\"Executing route_a2\")\n",
    "    return {\"result\": {\"result\": \"from route A2\"}, \"execution_order\": \"route_a2\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_b2(state):\n",
    "    print(\"Executing route_b2\")\n",
    "    return {\"result\": {\"result\": \"from route B2\"}, \"execution_order\": \"route_b2\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_c(state):\n",
    "    print(\"Executing route_c\")\n",
    "    return {\"result\": {\"result\": \"from route C\"}, \"execution_order\": \"route_c\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_d(state):\n",
    "    print(\"Executing route_d\")\n",
    "    return {\"result\": {\"result\": \"from route D\"}, \"execution_order\": \"route_d\"}\n",
    "\n",
    "\n",
    "# Add edges\n",
    "# graph.add_edge(START, \"process_data\")\n",
    "graph.add_router_edge(START, \"process_data\")  # No need to specify routes\n",
    "graph.add_edge(\"route_a\", \"route_a2\")\n",
    "graph.add_edge(\"route_b\", \"route_b2\")\n",
    "graph.add_edge(\"route_a2\", \"route_c\")\n",
    "graph.add_edge(\"route_b2\", \"route_c\")\n",
    "graph.add_edge(\"route_c\", \"route_d\")\n",
    "graph.add_edge(\"route_d\", END)\n",
    "\n",
    "# Execution will automatically handle routing\n",
    "graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.router_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.start()  # Will pause after process_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.execution_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "rprint(graph.detailed_execution_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "rprint(graph.detailed_execution_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprint(graph.execution_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph._update_execution_plan(\n",
    "    \"process_data\", graph.router_paths[\"process_data\"][\"route_a\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.router_paths[\"process_data\"][\"route_a\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.detailed_execution_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "class TestState(GraphState):\n",
    "    result: LastValue[dict]  # Store the result from routes\n",
    "    execution_order: History[str]  # Track execution order\n",
    "\n",
    "\n",
    "graph = Graph(state=TestState(result={}, execution_order=[]))\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def process_data(state):\n",
    "    print(\"Executing process_data\")\n",
    "    # Router node that returns a node name\n",
    "    if True:\n",
    "        return \"route_b\"\n",
    "    return \"route_a\"\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_a(state):\n",
    "    print(\"Executing route_a\")\n",
    "    return {\"result\": {\"result\": \"from route A\"}, \"execution_order\": \"route_a\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_b(state):\n",
    "    print(\"Executing route_b\")\n",
    "    return {\"result\": {\"result\": \"from route B\"}, \"execution_order\": \"route_b\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_a2(state):\n",
    "    print(\"Executing route_a2\")\n",
    "    return {\"result\": {\"result\": \"from route A2\"}, \"execution_order\": \"route_a2\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_b2(state):\n",
    "    print(\"Executing route_b2\")\n",
    "    if True:\n",
    "        return \"route_c\"\n",
    "    return \"route_d\"\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_c(state):\n",
    "    print(\"Executing route_c\")\n",
    "    return {\"result\": {\"result\": \"from route C\"}, \"execution_order\": \"route_c\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_d(state):\n",
    "    print(\"Executing route_d\")\n",
    "    return {\"result\": {\"result\": \"from route D\"}, \"execution_order\": \"route_d\"}\n",
    "\n",
    "\n",
    "# Add edges\n",
    "# graph.add_edge(START, \"process_data\")\n",
    "graph.add_router_edge(START, \"process_data\")  # No need to specify routes\n",
    "graph.add_edge(\"route_a\", \"route_a2\")\n",
    "# graph.add_edge(\"route_b\", \"route_b2\")\n",
    "graph.add_edge(\"route_a2\", \"route_c\")\n",
    "graph.add_router_edge(\"route_b\", \"route_b2\")\n",
    "graph.add_edge(\"route_c\", \"route_d\")\n",
    "graph.add_edge(\"route_d\", END)\n",
    "\n",
    "# Execution will automatically handle routing\n",
    "graph.compile()\n",
    "graph.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.router_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.execution_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.detailed_execution_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.detailed_execution_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "rprint(graph.execution_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "class TestState(GraphState):\n",
    "    result: LastValue[dict]  # Store the result from routes\n",
    "    execution_order: History[str]  # Track execution order\n",
    "\n",
    "\n",
    "graph = Graph(state=TestState(result={}, execution_order=[]))\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_a(state):\n",
    "    print(\"Executing route_a\")\n",
    "    return {\"result\": {\"result\": \"from route A\"}, \"execution_order\": \"route_a\"}\n",
    "\n",
    "\n",
    "@graph.node(interrupt=\"after\")\n",
    "def route_b(state):\n",
    "    print(\"Executing route_b\")\n",
    "    return {\"result\": {\"result\": \"from route B\"}, \"execution_order\": \"route_b\"}\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_c(state):\n",
    "    print(\"Executing route_c\")\n",
    "    if True:\n",
    "        return \"route_b\"\n",
    "    return \"route_d\"\n",
    "\n",
    "\n",
    "@graph.node()\n",
    "def route_d(state):\n",
    "    print(\"Executing route_d\")\n",
    "    return {\"result\": {\"result\": \"from route D\"}, \"execution_order\": \"route_d\"}\n",
    "\n",
    "\n",
    "# Add edges\n",
    "# graph.add_edge(START, \"process_data\")\n",
    "graph.add_edge(START, \"route_a\")  # No need to specify routes\n",
    "graph.add_edge(\"route_a\", \"route_b\")\n",
    "graph.add_router_edge(\"route_b\", \"route_c\")\n",
    "graph.add_edge(\"route_d\", END)\n",
    "\n",
    "# Execution will automatically handle routing\n",
    "graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.executed_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.next_execution_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.blocking_execution_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.execution_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.execution_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.execution_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Real World Example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cyclical planner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from primeGraph import Graph, START, END\n",
    "from primeGraph.models import GraphState\n",
    "from primeGraph.buffer import History, LastValue\n",
    "from rich import print as rprint\n",
    "from typing import Dict, Union, List, Any\n",
    "\n",
    "\n",
    "\n",
    "class State(GraphState):\n",
    "    conversation: History[Dict[str, str]]\n",
    "    model_message: LastValue[Union[str, None]] # Should be consumed by the bot before moving forward interruptions\n",
    "    user_message: LastValue[Union[str, None]] # Should be consumed by the bot before moving forward interruptions\n",
    "    is_followup: LastValue[Union[None, bool]]\n",
    "    is_forward_permission: LastValue[Union[bool, None]]\n",
    "    is_permission_granted: LastValue[Union[bool, None]]\n",
    "    is_outside_of_step: LastValue[Union[bool, None]]\n",
    "    plan_goal: LastValue[str]\n",
    "    plan_summary: LastValue[str]\n",
    "    plan_details: History[str]\n",
    "    is_ready_to_move_forward: LastValue[bool]\n",
    "    is_summary_approved: LastValue[bool]\n",
    "    interaction_summary: LastValue[str]\n",
    "    \n",
    "\n",
    "def generate_plan_graph(graph_state: State):\n",
    "    \n",
    "    plan_graph = Graph(graph_state, verbose=False)\n",
    "    \n",
    "\n",
    "    @plan_graph.node(interrupt=\"after\")\n",
    "    async def intitialize_conversation(state: State) -> dict[str, Any]:\n",
    "        print(\"Initializing conversation...\")\n",
    "        response = \"Welcome! Please tell me your goal in a single sentence.\"\n",
    "    \n",
    "        \n",
    "        return {\n",
    "            \"conversation\": {\"role\": \"assistant\", \"content\": response},\n",
    "            \"user_message\": None,\n",
    "            \"model_message\": response,\n",
    "        }\n",
    "\n",
    "    @plan_graph.node()\n",
    "    async def process_user_message(state: State) -> dict[str, Any]:\n",
    "        print(\"Processing user message...\")\n",
    "        \n",
    "        # Simulated response\n",
    "        response = \"I understand your goal. Let me ask a follow-up question.\"\n",
    "        plan_goal = \"Sample goal\"\n",
    "        plan_details = [\"Detail 1\", \"Detail 2\"]\n",
    "        \n",
    "        state.conversation.append({\"role\": \"user\", \"content\": state.user_message})\n",
    "        \n",
    "        # Add sample plan details\n",
    "        for detail in plan_details:\n",
    "            state.plan_details.append(detail)\n",
    "\n",
    "        return {\n",
    "            \"conversation\": {\"role\": \"assistant\", \"content\": response},\n",
    "            \"plan_goal\": plan_goal,\n",
    "            \"user_message\": None,\n",
    "            \"model_message\": response,\n",
    "            \"is_followup\": True,\n",
    "            \"is_forward_permission\": False,\n",
    "            \"is_outside_of_step\": False,\n",
    "        }\n",
    "    \n",
    "    @plan_graph.node()\n",
    "    async def response_router(state: State) -> str:\n",
    "        print(\"Routing response...\")\n",
    "        if state.is_followup:\n",
    "            return 'make_followup_questions'\n",
    "        elif state.is_forward_permission:\n",
    "            return 'summarize_and_ask_permission'\n",
    "        return END\n",
    "\n",
    "    @plan_graph.node(interrupt=\"before\")\n",
    "    async def make_followup_questions(state: State):\n",
    "        print(\"Making follow-up questions...\")\n",
    "        response = \"Here's a follow-up question for clarification.\"\n",
    "        plan_details = [\"Follow-up detail 1\", \"Follow-up detail 2\"]\n",
    "        \n",
    "        state.conversation.append({\"role\": \"user\", \"content\": state.user_message})\n",
    "        \n",
    "        for detail in plan_details:\n",
    "            state.plan_details.append(detail)\n",
    "\n",
    "        return {\n",
    "            \"conversation\": {\"role\": \"assistant\", \"content\": response},\n",
    "            \"user_message\": None,\n",
    "            \"model_message\": response,\n",
    "            \"is_followup\": True,\n",
    "            \"is_forward_permission\": False,\n",
    "            \"is_outside_of_step\": False,\n",
    "        }\n",
    "    \n",
    "    @plan_graph.node()\n",
    "    async def check_followup_next_step(state: State):\n",
    "        print(\"Checking follow-up next step...\")\n",
    "        if state.is_followup:\n",
    "            return 'make_followup_questions'\n",
    "        return 'summarize_and_ask_permission'\n",
    "\n",
    "    @plan_graph.node(interrupt=\"before\")\n",
    "    async def summarize_and_ask_permission(state: State):\n",
    "        print(\"Summarizing and asking for permission...\")\n",
    "        response = \"Here's a summary of our discussion. Shall we move forward?\"\n",
    "        \n",
    "        state.conversation.append({\"role\": \"user\", \"content\": state.user_message})\n",
    "\n",
    "        return {\n",
    "            \"conversation\": {\"role\": \"assistant\", \"content\": response},\n",
    "            \"user_message\": None,\n",
    "            \"model_message\": response,\n",
    "            \"is_followup\": False,\n",
    "            \"is_permission_granted\": True,\n",
    "            \"is_outside_of_step\": False,\n",
    "        }\n",
    "    \n",
    "    @plan_graph.node()\n",
    "    async def move_to_next_step(state: State):\n",
    "        print(\"Moving to next step...\")\n",
    "        if state.is_permission_granted:\n",
    "            return END\n",
    "        return 'process_user_message'\n",
    "\n",
    "\n",
    "    plan_graph.add_edge(START, 'intitialize_conversation')\n",
    "    plan_graph.add_edge('intitialize_conversation', 'process_user_message')\n",
    "    plan_graph.add_router_edge('process_user_message', 'response_router')\n",
    "    plan_graph.add_router_edge('make_followup_questions', 'check_followup_next_step')\n",
    "\n",
    "    plan_graph.add_router_edge(\"summarize_and_ask_permission\", \"move_to_next_step\")\n",
    "    \n",
    "    \n",
    "    plan_graph.compile()\n",
    "\n",
    "    return plan_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plan_graph_state = State(conversation=[], \n",
    "                         model_message=None, \n",
    "                         user_message=None,\n",
    "                         next_interaction={\"worflow_step\": \"user_prompt\"}, \n",
    "                         plan_goal=\"\", \n",
    "                         plan_summary=\"\", \n",
    "                         plan_details=[], \n",
    "                         is_summary_approved=False, \n",
    "                         interaction_summary=\"\", \n",
    "                         is_followup=False,\n",
    "                         is_forward_permission=False,\n",
    "                         is_permission_granted=False,\n",
    "                         is_outside_of_step=False,\n",
    "                         is_ready_to_move_forward=False)\n",
    "\n",
    "graph = generate_plan_graph(plan_graph_state)\n",
    "\n",
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await graph.start_async()\n",
    "rprint(plan_graph_state)\n",
    "rprint(graph.chain_status)\n",
    "rprint(graph.next_execution_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.update_state_and_checkpoint({\"user_message\": \"I to plan a wedding party\"})\n",
    "await graph.resume_async()\n",
    "rprint(plan_graph_state)\n",
    "rprint(graph.chain_status)\n",
    "rprint(graph.next_execution_node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.update_state_and_checkpoint({\"user_message\": \"I to plan a wedding party\"})\n",
    "await graph.resume_async()\n",
    "rprint(plan_graph_state)\n",
    "rprint(graph.chain_status)\n",
    "rprint(graph.next_execution_node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pdb\n",
    "\n",
    "graph.update_state_and_checkpoint({\"user_message\": \"I to plan a wedding party\"})\n",
    "await graph.resume_async()\n",
    "rprint(plan_graph_state)\n",
    "rprint(graph.chain_status)\n",
    "rprint(graph.next_execution_node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.start_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.start_from = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprint(graph.execution_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.is_cyclical_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.executed_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cyclical planner - storage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from primeGraph import Graph, START, END\n",
    "import instructor\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from primeGraph.models import GraphState\n",
    "from primeGraph.buffer import History, LastValue\n",
    "from rich import print as rprint\n",
    "from typing import Dict, Union, List\n",
    "from primeGraph.checkpoint.postgresql import PostgreSQLStorage\n",
    "from rich import print as rprint\n",
    "\n",
    "\n",
    "sys_prompt_0 = \"\"\"\n",
    "Give the user a welcome message and ask them to state their goal in a single sentence.\n",
    "\"\"\"\n",
    "\n",
    "sys_prompt_1 = \"\"\"\n",
    "You are in a planning workflow in this is the first step. Execute all the instructions below exactly as they are.\n",
    "\n",
    "Phase 1: Goal Understanding\n",
    "\n",
    "Ask the user to state their goal in a single sentence\n",
    "Have them specify what success looks like for this goal\n",
    "Determine if there are any absolute constraints or requirements\n",
    "\n",
    "If the goal is clear, just say \"Ok, I got it\"\n",
    "\n",
    "Guidelines Throughout Process\n",
    "DO:\n",
    "\n",
    "Keep questions focused on structural elements\n",
    "Maintain high-level perspective\n",
    "Validate understanding frequently\n",
    "Document assumptions made\n",
    "\n",
    "DON'T:\n",
    "\n",
    "Ask about specific implementation steps\n",
    "Get caught up in technical details\n",
    "Try to solve problems at this stage\n",
    "Make decisions about execution methods\n",
    "\n",
    "Red Flags to Watch For\n",
    "\n",
    "Discussion becoming too detailed\n",
    "Questions about \"how\" instead of \"what\"\n",
    "Focus shifting to specific solutions\n",
    "Getting stuck on implementation challenges\n",
    "\n",
    "Remember: The goal is to create a clear framework for the plan, not to determine how each piece will be executed.\n",
    "\"\"\"\n",
    "\n",
    "sys_prompt_2 = \"\"\"\n",
    "You are in a planning workflow in this is the first step. Execute all the instructions below exactly as they are.\n",
    "\n",
    "    Phase 2: Information Gathering\n",
    "\n",
    "Ask clarifying questions focusing only on high-level aspects:\n",
    "\n",
    "What are the major components or phases?\n",
    "Who are the key stakeholders?\n",
    "What are the critical dependencies?\n",
    "What resources are already available?\n",
    "\n",
    "\n",
    "For each unclear point:\n",
    "\n",
    "Ask one focused question at a time\n",
    "Avoid diving into implementation details\n",
    "Capture only information relevant to overall structure\n",
    "\n",
    "Guidelines Throughout Process\n",
    "DO:\n",
    "\n",
    "Keep questions focused on structural elements\n",
    "Maintain high-level perspective\n",
    "Validate understanding frequently\n",
    "Document assumptions made\n",
    "\n",
    "DON'T:\n",
    "\n",
    "Ask about specific implementation steps\n",
    "Get caught up in technical details\n",
    "Try to solve problems at this stage\n",
    "Make decisions about execution methods\n",
    "\n",
    "Red Flags to Watch For\n",
    "\n",
    "Discussion becoming too detailed\n",
    "Questions about \"how\" instead of \"what\"\n",
    "Focus shifting to specific solutions\n",
    "Getting stuck on implementation challenges\n",
    "\n",
    "Remember: The goal is to create a clear framework for the plan, not to determine how each piece will be executed.\n",
    "\"\"\"\n",
    "\n",
    "sys_prompt_3 = \"\"\"\n",
    "You are in a planning workflow in this is the first step. Execute all the instructions below exactly as they are.\n",
    "Phase 3: Plan Summary & Validation\n",
    "\n",
    "Create a structured summary including:\n",
    "\n",
    "Main goal statement\n",
    "Key success criteria\n",
    "Major components identified\n",
    "Critical dependencies\n",
    "High-level timeline\n",
    "Key stakeholders\n",
    "\n",
    "\n",
    "Present the summary to user:\n",
    "\n",
    "Ask if anything major is missing\n",
    "Confirm if the interpretation is correct\n",
    "Verify if the level of detail is appropriate\n",
    "\n",
    "How to present: \n",
    "\n",
    "- Strucutre things in a way that is easy to understand like: \n",
    "    - Use bullet points\n",
    "    - Use numbered lists\n",
    "    - Use tables\n",
    "    - Use markdown\n",
    "- Make it visually appealing\n",
    "\n",
    "\n",
    "\n",
    "Guidelines Throughout Process\n",
    "DO:\n",
    "\n",
    "Keep questions focused on structural elements\n",
    "Maintain high-level perspective\n",
    "Validate understanding frequently\n",
    "Document assumptions made\n",
    "\n",
    "DON'T:\n",
    "\n",
    "Ask about specific implementation steps\n",
    "Get caught up in technical details\n",
    "Try to solve problems at this stage\n",
    "Make decisions about execution methods\n",
    "\n",
    "Red Flags to Watch For\n",
    "\n",
    "Discussion becoming too detailed\n",
    "Questions about \"how\" instead of \"what\"\n",
    "Focus shifting to specific solutions\n",
    "Getting stuck on implementation challenges\n",
    "\n",
    "Remember: The goal is to create a clear framework for the plan, not to determine how each piece will be executed.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "storage = PostgreSQLStorage.from_config(\n",
    "    host=\"localhost\",\n",
    "    port=5432,\n",
    "    user=\"primegraph\",\n",
    "    password=\"primegraph\",\n",
    "    database=\"primegraph\",\n",
    ")\n",
    "\n",
    "class PlannerState(GraphState):\n",
    "    conversation: History[Dict[str, str]] = Field(default_factory=list)\n",
    "    model_message: LastValue[Union[str, None]] = Field(\n",
    "        default=None\n",
    "    )  # Should be consumed by the bot before moving forward interruptions\n",
    "    user_message: LastValue[Union[str, None]] = Field(\n",
    "        default=None\n",
    "    )  # Should be consumed by the bot before moving forward interruptions\n",
    "    is_followup: LastValue[Union[None, bool]] = Field(default=None)\n",
    "    is_forward_permission: LastValue[Union[bool, None]] = Field(default=None)\n",
    "    is_permission_granted: LastValue[Union[bool, None]] = Field(default=None)\n",
    "    is_outside_of_step: LastValue[Union[bool, None]] = Field(default=None)\n",
    "    plan_goal: LastValue[str] = Field(default=\"\")\n",
    "    plan_summary: LastValue[str] = Field(default=\"\")\n",
    "    plan_details: History[str] = Field(default_factory=list)\n",
    "    is_ready_to_move_forward: LastValue[bool] = Field(default=False)\n",
    "    is_summary_approved: LastValue[bool] = Field(default=False)\n",
    "    interaction_summary: LastValue[str] = Field(default=\"\")\n",
    "\n",
    "\n",
    "def planner_graph(graph_state: PlannerState, graph_storage: Union[PostgreSQLStorage, None]) -> Graph:\n",
    "    plan_graph = Graph(state=graph_state, verbose=True, checkpoint_storage=graph_storage)\n",
    "    client = instructor.from_openai(OpenAI())\n",
    "\n",
    "    @plan_graph.node()\n",
    "    def process_user_message(state: PlannerState) -> dict[str, Any]:\n",
    "        class ProcessMessageResponse(BaseModel):\n",
    "            plan_goal: str = Field(description=\"The main goal of the plan\")\n",
    "            plan_details: List[str] = Field(description=\"Any additional relevant details of the plan\")\n",
    "            response: str = Field(description=\"Your response to the user\")\n",
    "            is_followup: bool = Field(description=\"If you need to ask follow up questions\")\n",
    "            is_forward_permission: bool = Field(description=\"If there are not follow up questions on your end.\")\n",
    "            is_outside_of_step: bool = Field(\n",
    "                description=\"If the user is explicitly asking to move out of the plan workflow\"\n",
    "            )\n",
    "\n",
    "        # Extract structured data from natural language\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            response_model=ProcessMessageResponse,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt_1},\n",
    "                *state.conversation,\n",
    "                {\"role\": \"user\", \"content\": state.user_message},\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        if state.user_message:\n",
    "            state.conversation.append({\"role\": \"user\", \"content\": state.user_message})\n",
    "\n",
    "        # unpack plan_details:\n",
    "        if completion.plan_details:\n",
    "            for detail in completion.plan_details:\n",
    "                state.plan_details.append(detail)\n",
    "\n",
    "        return {\n",
    "            \"conversation\": {\"role\": \"assistant\", \"content\": completion.response},\n",
    "            \"plan_goal\": completion.plan_goal,\n",
    "            \"user_message\": None,\n",
    "            \"model_message\": completion.response,\n",
    "            \"is_followup\": completion.is_followup,\n",
    "            \"is_forward_permission\": completion.is_forward_permission,\n",
    "            \"is_outside_of_step\": completion.is_outside_of_step,\n",
    "        }\n",
    "\n",
    "    @plan_graph.node()\n",
    "    def response_router(state: PlannerState) -> str:\n",
    "        if state.is_followup:\n",
    "            return \"make_followup_questions\"\n",
    "        elif state.is_forward_permission:\n",
    "            return \"summarize_and_ask_permission\"\n",
    "        return END\n",
    "\n",
    "    @plan_graph.node(interrupt=\"before\")\n",
    "    def make_followup_questions(state: PlannerState):\n",
    "        class FollowupResponse(BaseModel):\n",
    "            plan_details: List[str] = Field(description=\"Any additional you got from your follow up questions\")\n",
    "            response: str = Field(description=\"Your response to the user\")\n",
    "            is_followup: bool = Field(description=\"If you need to ask follow up questions\")\n",
    "            is_forward_permission: bool = Field(description=\"If the user is asking to move forward to the next step\")\n",
    "            is_outside_of_step: bool = Field(\n",
    "                description=\"If the user is explicitly asking to move out of the plan workflow\"\n",
    "            )\n",
    "\n",
    "        # Extract structured data from natural language\n",
    "\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            response_model=FollowupResponse,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt_2},\n",
    "                *state.conversation,\n",
    "                {\"role\": \"user\", \"content\": state.user_message},\n",
    "            ],\n",
    "        )\n",
    "        if state.user_message:\n",
    "            state.conversation.append({\"role\": \"user\", \"content\": state.user_message})\n",
    "\n",
    "        rprint(completion)\n",
    "        # unpack plan_details:\n",
    "        if completion.plan_details:\n",
    "            for detail in completion.plan_details:\n",
    "                state.plan_details.append(detail)\n",
    "\n",
    "        return {\n",
    "            \"conversation\": {\"role\": \"assistant\", \"content\": completion.response},\n",
    "            \"user_message\": None,\n",
    "            \"model_message\": completion.response,\n",
    "            \"is_followup\": completion.is_followup,\n",
    "            \"is_forward_permission\": completion.is_forward_permission,\n",
    "            \"is_outside_of_step\": completion.is_outside_of_step,\n",
    "        }\n",
    "\n",
    "    @plan_graph.node()\n",
    "    def check_followup_next_step(state: PlannerState):\n",
    "        if state.is_followup:\n",
    "            return \"make_followup_questions\"\n",
    "        else:\n",
    "            return \"summarize_and_ask_permission\"\n",
    "\n",
    "    @plan_graph.node(interrupt=\"before\")\n",
    "    def summarize_and_ask_permission(state: PlannerState):\n",
    "        class PermissionResponse(BaseModel):\n",
    "            response: str = Field(description=\"Your response to the user\")\n",
    "            is_followup: bool = Field(description=\"If you need to ask follow up questions\")\n",
    "            is_outside_of_step: bool = Field(description=\"If the user is explicitly asking to move to a different step\")\n",
    "            is_permission_granted: bool = Field(description=\"If the user authorized moving to the next step\")\n",
    "\n",
    "        # Extract structured data from natural language\n",
    "\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            response_model=PermissionResponse,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt_3},\n",
    "                *state.conversation,\n",
    "                {\"role\": \"user\", \"content\": state.user_message},\n",
    "            ],\n",
    "        )\n",
    "        if state.user_message:\n",
    "            state.conversation.append({\"role\": \"user\", \"content\": state.user_message})\n",
    "\n",
    "        return {\n",
    "            \"conversation\": {\"role\": \"assistant\", \"content\": completion.response},\n",
    "            \"user_message\": None,\n",
    "            \"model_message\": completion.response,\n",
    "            \"is_followup\": completion.is_followup,\n",
    "            \"is_permission_granted\": completion.is_permission_granted,\n",
    "            \"is_outside_of_step\": completion.is_outside_of_step,\n",
    "        }\n",
    "\n",
    "\n",
    "    @plan_graph.node()\n",
    "    def move_to_next_step(state: PlannerState):\n",
    "        if state.is_permission_granted:\n",
    "            return END\n",
    "        else:\n",
    "            return \"process_user_message\"\n",
    "\n",
    "    plan_graph.add_edge(START, \"process_user_message\")\n",
    "    plan_graph.add_router_edge(\"process_user_message\", \"response_router\")\n",
    "    plan_graph.add_router_edge(\"make_followup_questions\", \"check_followup_next_step\")\n",
    "\n",
    "    plan_graph.add_router_edge(\"summarize_and_ask_permission\", \"move_to_next_step\")\n",
    "\n",
    "    plan_graph.compile()\n",
    "\n",
    "    return plan_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.2.1 (20241206.2353)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"344pt\" height=\"780pt\"\n",
       " viewBox=\"21.60 21.60 322.10 758.83\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(25.6 754.83)\">\n",
       "<!-- __start__ -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>__start__</title>\n",
       "<ellipse fill=\"#f4e8e8\" stroke=\"black\" cx=\"226.35\" cy=\"-711.1\" rx=\"49\" ry=\"18.14\"/>\n",
       "<text text-anchor=\"middle\" x=\"226.35\" y=\"-707.22\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">__start__</text>\n",
       "</g>\n",
       "<!-- process_user_message -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>process_user_message</title>\n",
       "<path fill=\"lightblue\" stroke=\"black\" d=\"M280.5,-663.96C280.5,-663.96 172.2,-663.96 172.2,-663.96 166.2,-663.96 160.2,-657.96 160.2,-651.96 160.2,-651.96 160.2,-639.96 160.2,-639.96 160.2,-633.96 166.2,-627.96 172.2,-627.96 172.2,-627.96 280.5,-627.96 280.5,-627.96 286.5,-627.96 292.5,-633.96 292.5,-639.96 292.5,-639.96 292.5,-651.96 292.5,-651.96 292.5,-657.96 286.5,-663.96 280.5,-663.96\"/>\n",
       "<text text-anchor=\"middle\" x=\"226.35\" y=\"-642.08\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">process_user_message</text>\n",
       "</g>\n",
       "<!-- __start__&#45;&gt;process_user_message -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>__start__&#45;&gt;process_user_message</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M226.35,-692.6C226.35,-692.6 226.35,-675.78 226.35,-675.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"229.85,-675.78 226.35,-665.78 222.85,-675.78 229.85,-675.78\"/>\n",
       "</g>\n",
       "<!-- __end__ -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>__end__</title>\n",
       "<ellipse fill=\"#f4e8e8\" stroke=\"black\" cx=\"64.35\" cy=\"-18.14\" rx=\"46.35\" ry=\"18.14\"/>\n",
       "<text text-anchor=\"middle\" x=\"64.35\" y=\"-14.26\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">__end__</text>\n",
       "</g>\n",
       "<!-- response_router -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>response_router</title>\n",
       "<path fill=\"#ffe4b5\" stroke=\"black\" d=\"M173.87,-590.47C173.87,-590.47 135.75,-552.36 135.75,-552.36 131.51,-548.12 131.51,-539.63 135.75,-535.39 135.75,-535.39 173.87,-497.28 173.87,-497.28 178.11,-493.03 186.59,-493.03 190.84,-497.28 190.84,-497.28 228.95,-535.39 228.95,-535.39 233.19,-539.63 233.19,-548.12 228.95,-552.36 228.95,-552.36 190.84,-590.47 190.84,-590.47 186.59,-594.72 178.11,-594.72 173.87,-590.47\"/>\n",
       "<text text-anchor=\"middle\" x=\"182.35\" y=\"-545.62\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">response</text>\n",
       "<text text-anchor=\"middle\" x=\"182.35\" y=\"-534.37\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">router</text>\n",
       "</g>\n",
       "<!-- process_user_message&#45;&gt;response_router -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>process_user_message&#45;&gt;response_router</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M198.82,-627.71C198.82,-627.71 198.82,-594.63 198.82,-594.63\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"202.32,-594.63 198.82,-584.63 195.32,-594.63 202.32,-594.63\"/>\n",
       "</g>\n",
       "<!-- response_router&#45;&gt;__end__ -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>response_router&#45;&gt;__end__</title>\n",
       "<path fill=\"none\" stroke=\"#666666\" stroke-dasharray=\"5,2\" d=\"M127.14,-544C73.47,-544 0,-544 0,-544 0,-544 0,-18 0,-18 0,-18 6.07,-18 6.07,-18\"/>\n",
       "<polygon fill=\"#666666\" stroke=\"#666666\" points=\"6.07,-21.5 16.07,-18 6.07,-14.5 6.07,-21.5\"/>\n",
       "</g>\n",
       "<!-- make_followup_questions -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>make_followup_questions</title>\n",
       "<path fill=\"lightblue\" stroke=\"#666666\" d=\"M30.68,-423.29C30.68,-423.29 230.03,-423.29 230.03,-423.29 236.03,-423.29 242.03,-429.29 242.03,-435.29 242.03,-435.29 242.03,-447.29 242.03,-447.29 242.03,-453.29 236.03,-459.29 230.03,-459.29 230.03,-459.29 30.68,-459.29 30.68,-459.29 24.68,-459.29 18.68,-453.29 18.68,-447.29 18.68,-447.29 18.68,-435.29 18.68,-435.29 18.68,-429.29 24.68,-423.29 30.68,-423.29\"/>\n",
       "<text text-anchor=\"start\" x=\"33.08\" y=\"-438.42\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" fill=\"#aa0000\">●</text>\n",
       "<text text-anchor=\"start\" x=\"39.08\" y=\"-438.42\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\"> </text>\n",
       "<text text-anchor=\"start\" x=\"42.08\" y=\"-438.42\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"10.00\">Int. before</text>\n",
       "<polyline fill=\"none\" stroke=\"#666666\" points=\"100.73,-423.29 100.73,-459.29\"/>\n",
       "<text text-anchor=\"start\" x=\"115.13\" y=\"-437.42\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">make_followup_questions</text>\n",
       "</g>\n",
       "<!-- response_router&#45;&gt;make_followup_questions -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>response_router&#45;&gt;make_followup_questions</title>\n",
       "<path fill=\"none\" stroke=\"#666666\" stroke-dasharray=\"5,2\" d=\"M182.35,-488.38C182.35,-488.38 182.35,-471.15 182.35,-471.15\"/>\n",
       "<polygon fill=\"#666666\" stroke=\"#666666\" points=\"185.85,-471.15 182.35,-461.15 178.85,-471.15 185.85,-471.15\"/>\n",
       "</g>\n",
       "<!-- summarize_and_ask_permission -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>summarize_and_ask_permission</title>\n",
       "<path fill=\"lightblue\" stroke=\"#666666\" d=\"M38.68,-202.77C38.68,-202.77 268.03,-202.77 268.03,-202.77 274.03,-202.77 280.03,-208.77 280.03,-214.77 280.03,-214.77 280.03,-226.77 280.03,-226.77 280.03,-232.77 274.03,-238.77 268.03,-238.77 268.03,-238.77 38.68,-238.77 38.68,-238.77 32.68,-238.77 26.68,-232.77 26.68,-226.77 26.68,-226.77 26.68,-214.77 26.68,-214.77 26.68,-208.77 32.68,-202.77 38.68,-202.77\"/>\n",
       "<text text-anchor=\"start\" x=\"41.08\" y=\"-217.9\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" fill=\"#aa0000\">●</text>\n",
       "<text text-anchor=\"start\" x=\"47.08\" y=\"-217.9\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\"> </text>\n",
       "<text text-anchor=\"start\" x=\"50.08\" y=\"-217.9\" font-family=\"Helvetica,sans-Serif\" font-style=\"italic\" font-size=\"10.00\">Int. before</text>\n",
       "<polyline fill=\"none\" stroke=\"#666666\" points=\"108.73,-202.77 108.73,-238.77\"/>\n",
       "<text text-anchor=\"start\" x=\"123.13\" y=\"-216.9\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">summarize_and_ask_permission</text>\n",
       "</g>\n",
       "<!-- response_router&#45;&gt;summarize_and_ask_permission -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>response_router&#45;&gt;summarize_and_ask_permission</title>\n",
       "<path fill=\"none\" stroke=\"#666666\" stroke-dasharray=\"5,2\" d=\"M237.85,-544C250.86,-544 261.03,-544 261.03,-544 261.03,-544 261.03,-250.59 261.03,-250.59\"/>\n",
       "<polygon fill=\"#666666\" stroke=\"#666666\" points=\"264.53,-250.59 261.03,-240.59 257.53,-250.59 264.53,-250.59\"/>\n",
       "</g>\n",
       "<!-- check_followup_next_step -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>check_followup_next_step</title>\n",
       "<path fill=\"#ffe4b5\" stroke=\"black\" d=\"M121.87,-385.31C121.87,-385.31 76.08,-339.52 76.08,-339.52 71.83,-335.28 71.83,-326.79 76.08,-322.55 76.08,-322.55 121.87,-276.76 121.87,-276.76 126.11,-272.52 134.59,-272.52 138.84,-276.76 138.84,-276.76 184.62,-322.55 184.62,-322.55 188.87,-326.79 188.87,-335.28 184.62,-339.52 184.62,-339.52 138.84,-385.31 138.84,-385.31 134.59,-389.55 126.11,-389.55 121.87,-385.31\"/>\n",
       "<text text-anchor=\"middle\" x=\"130.35\" y=\"-344.03\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">check</text>\n",
       "<text text-anchor=\"middle\" x=\"130.35\" y=\"-332.78\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">followup</text>\n",
       "<text text-anchor=\"middle\" x=\"130.35\" y=\"-321.53\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">next</text>\n",
       "<text text-anchor=\"middle\" x=\"130.35\" y=\"-310.28\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">step</text>\n",
       "</g>\n",
       "<!-- make_followup_questions&#45;&gt;check_followup_next_step -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>make_followup_questions&#45;&gt;check_followup_next_step</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M109.43,-423.08C109.43,-423.08 109.43,-385.09 109.43,-385.09\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"112.93,-385.09 109.43,-375.09 105.93,-385.09 112.93,-385.09\"/>\n",
       "</g>\n",
       "<!-- check_followup_next_step&#45;&gt;make_followup_questions -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>check_followup_next_step&#45;&gt;make_followup_questions</title>\n",
       "<path fill=\"none\" stroke=\"#666666\" stroke-dasharray=\"5,2\" d=\"M151.27,-373.35C151.27,-373.35 151.27,-411.33 151.27,-411.33\"/>\n",
       "<polygon fill=\"#666666\" stroke=\"#666666\" points=\"147.77,-411.33 151.27,-421.33 154.77,-411.33 147.77,-411.33\"/>\n",
       "</g>\n",
       "<!-- check_followup_next_step&#45;&gt;summarize_and_ask_permission -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>check_followup_next_step&#45;&gt;summarize_and_ask_permission</title>\n",
       "<path fill=\"none\" stroke=\"#666666\" stroke-dasharray=\"5,2\" d=\"M130.35,-267.85C130.35,-267.85 130.35,-250.43 130.35,-250.43\"/>\n",
       "<polygon fill=\"#666666\" stroke=\"#666666\" points=\"133.85,-250.43 130.35,-240.43 126.85,-250.43 133.85,-250.43\"/>\n",
       "</g>\n",
       "<!-- move_to_next_step -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>move_to_next_step</title>\n",
       "<path fill=\"#ffe4b5\" stroke=\"black\" d=\"M144.87,-164.79C144.87,-164.79 107.84,-127.76 107.84,-127.76 103.59,-123.52 103.59,-115.03 107.84,-110.79 107.84,-110.79 144.87,-73.76 144.87,-73.76 149.11,-69.52 157.59,-69.52 161.84,-73.76 161.84,-73.76 198.87,-110.79 198.87,-110.79 203.11,-115.03 203.11,-123.52 198.87,-127.76 198.87,-127.76 161.84,-164.79 161.84,-164.79 157.59,-169.03 149.11,-169.03 144.87,-164.79\"/>\n",
       "<text text-anchor=\"middle\" x=\"153.35\" y=\"-132.27\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">move</text>\n",
       "<text text-anchor=\"middle\" x=\"153.35\" y=\"-121.02\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">to</text>\n",
       "<text text-anchor=\"middle\" x=\"153.35\" y=\"-109.77\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">next</text>\n",
       "<text text-anchor=\"middle\" x=\"153.35\" y=\"-98.52\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">step</text>\n",
       "</g>\n",
       "<!-- summarize_and_ask_permission&#45;&gt;move_to_next_step -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>summarize_and_ask_permission&#45;&gt;move_to_next_step</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M153.35,-202.63C153.35,-202.63 153.35,-185.34 153.35,-185.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"156.85,-185.34 153.35,-175.34 149.85,-185.34 156.85,-185.34\"/>\n",
       "</g>\n",
       "<!-- move_to_next_step&#45;&gt;__end__ -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>move_to_next_step&#45;&gt;__end__</title>\n",
       "<path fill=\"none\" stroke=\"#666666\" stroke-dasharray=\"5,2\" d=\"M105.03,-112.95C105.03,-112.95 105.03,-38.79 105.03,-38.79\"/>\n",
       "<polygon fill=\"#666666\" stroke=\"#666666\" points=\"108.53,-38.79 105.03,-28.79 101.53,-38.79 108.53,-38.79\"/>\n",
       "</g>\n",
       "<!-- move_to_next_step&#45;&gt;process_user_message -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>move_to_next_step&#45;&gt;process_user_message</title>\n",
       "<path fill=\"none\" stroke=\"#666666\" stroke-dasharray=\"5,2\" d=\"M207.41,-119C244.21,-119 286.26,-119 286.26,-119 286.26,-119 286.26,-616 286.26,-616\"/>\n",
       "<polygon fill=\"#666666\" stroke=\"#666666\" points=\"282.76,-616 286.26,-626 289.76,-616 282.76,-616\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x112367950>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plan_graph_state = PlannerState()\n",
    "\n",
    "graph = planner_graph(plan_graph_state, graph_storage=storage)\n",
    "\n",
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PlannerState</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">version</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'44f1c3426cd72a291e94142dfe5e0c75'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">conversation</span>=<span style=\"font-weight: bold\">[{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Please state your goal in a single sentence.'</span><span style=\"font-weight: bold\">}]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model_message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Please state your goal in a single sentence.'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">user_message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_followup</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_forward_permission</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_permission_granted</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_outside_of_step</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_goal</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_summary</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_details</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_ready_to_move_forward</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_summary_approved</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">interaction_summary</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mPlannerState\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mversion\u001b[0m=\u001b[32m'44f1c3426cd72a291e94142dfe5e0c75'\u001b[0m,\n",
       "    \u001b[33mconversation\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'Please state your goal in a single sentence.'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mmodel_message\u001b[0m=\u001b[32m'Please state your goal in a single sentence.'\u001b[0m,\n",
       "    \u001b[33muser_message\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mis_followup\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[33mis_forward_permission\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33mis_permission_granted\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mis_outside_of_step\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33mplan_goal\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "    \u001b[33mplan_summary\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "    \u001b[33mplan_details\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mis_ready_to_move_forward\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33mis_summary_approved\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33minteraction_summary\u001b[0m=\u001b[32m''\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ChainStatus.PAUSE\n",
       "</pre>\n"
      ],
      "text/plain": [
       "ChainStatus.PAUSE\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">make_followup_questions\n",
       "</pre>\n"
      ],
      "text/plain": [
       "make_followup_questions\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chain_id = await graph.start_async()\n",
    "rprint(plan_graph_state)\n",
    "rprint(graph.chain_status)\n",
    "rprint(graph.next_execution_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_pre_checkpoint\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PlannerState</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">version</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'44f1c3426cd72a291e94142dfe5e0c75'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">conversation</span>=<span style=\"font-weight: bold\">[{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Please state your goal in a single sentence.'</span><span style=\"font-weight: bold\">}]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model_message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Please state your goal in a single sentence.'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">user_message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'I want to plan a wedding party'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_followup</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_forward_permission</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_permission_granted</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_outside_of_step</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_goal</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_summary</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_details</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_ready_to_move_forward</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_summary_approved</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">interaction_summary</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mPlannerState\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mversion\u001b[0m=\u001b[32m'44f1c3426cd72a291e94142dfe5e0c75'\u001b[0m,\n",
       "    \u001b[33mconversation\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'Please state your goal in a single sentence.'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mmodel_message\u001b[0m=\u001b[32m'Please state your goal in a single sentence.'\u001b[0m,\n",
       "    \u001b[33muser_message\u001b[0m=\u001b[32m'I want to plan a wedding party'\u001b[0m,\n",
       "    \u001b[33mis_followup\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[33mis_forward_permission\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33mis_permission_granted\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mis_outside_of_step\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33mplan_goal\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "    \u001b[33mplan_summary\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "    \u001b[33mplan_details\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mis_ready_to_move_forward\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33mis_summary_approved\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33minteraction_summary\u001b[0m=\u001b[32m''\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">FollowupResponse</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_details</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"To begin planning your wedding party, I need to gather some high-level information:\\n\\n1. What are </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the major components or phases you've identified for the wedding party? \\n2. Who are the key stakeholders involved </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">in your wedding planning?\\n3. Have you identified any critical dependencies that should be considered?\\n4. What </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">resources (venues, budget, team members, etc.) are already available to you?\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_followup</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_forward_permission</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_outside_of_step</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mFollowupResponse\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mplan_details\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mresponse\u001b[0m=\u001b[32m\"To\u001b[0m\u001b[32m begin planning your wedding party, I need to gather some high-level information:\\n\\n1. What are \u001b[0m\n",
       "\u001b[32mthe major components or phases you've identified for the wedding party? \\n2. Who are the key stakeholders involved \u001b[0m\n",
       "\u001b[32min your wedding planning?\\n3. Have you identified any critical dependencies that should be considered?\\n4. What \u001b[0m\n",
       "\u001b[32mresources \u001b[0m\u001b[32m(\u001b[0m\u001b[32mvenues, budget, team members, etc.\u001b[0m\u001b[32m)\u001b[0m\u001b[32m are already available to you?\"\u001b[0m,\n",
       "    \u001b[33mis_followup\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[33mis_forward_permission\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33mis_outside_of_step\u001b[0m=\u001b[3;91mFalse\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_post_checkpoint\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PlannerState</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">version</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'44f1c3426cd72a291e94142dfe5e0c75'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">conversation</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Please state your goal in a single sentence.'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I want to plan a wedding party'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"To begin planning your wedding party, I need to gather some high-level information:\\n\\n1. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">What are the major components or phases you've identified for the wedding party? \\n2. Who are the key stakeholders </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">involved in your wedding planning?\\n3. Have you identified any critical dependencies that should be considered?\\n4.</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">What resources (venues, budget, team members, etc.) are already available to you?\"</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model_message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"To begin planning your wedding party, I need to gather some high-level information:\\n\\n1. What </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">are the major components or phases you've identified for the wedding party? \\n2. Who are the key stakeholders </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">involved in your wedding planning?\\n3. Have you identified any critical dependencies that should be considered?\\n4.</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">What resources (venues, budget, team members, etc.) are already available to you?\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">user_message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_followup</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_forward_permission</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_permission_granted</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_outside_of_step</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_goal</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_summary</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_details</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_ready_to_move_forward</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_summary_approved</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">interaction_summary</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mPlannerState\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mversion\u001b[0m=\u001b[32m'44f1c3426cd72a291e94142dfe5e0c75'\u001b[0m,\n",
       "    \u001b[33mconversation\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'Please state your goal in a single sentence.'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'user'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'I want to plan a wedding party'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m,\n",
       "            \u001b[32m'content'\u001b[0m: \u001b[32m\"To begin planning your wedding party, I need to gather some high-level information:\\n\\n1. \u001b[0m\n",
       "\u001b[32mWhat are the major components or phases you've identified for the wedding party? \\n2. Who are the key stakeholders \u001b[0m\n",
       "\u001b[32minvolved in your wedding planning?\\n3. Have you identified any critical dependencies that should be considered?\\n4.\u001b[0m\n",
       "\u001b[32mWhat resources \u001b[0m\u001b[32m(\u001b[0m\u001b[32mvenues, budget, team members, etc.\u001b[0m\u001b[32m)\u001b[0m\u001b[32m are already available to you?\"\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mmodel_message\u001b[0m=\u001b[32m\"To\u001b[0m\u001b[32m begin planning your wedding party, I need to gather some high-level information:\\n\\n1. What \u001b[0m\n",
       "\u001b[32mare the major components or phases you've identified for the wedding party? \\n2. Who are the key stakeholders \u001b[0m\n",
       "\u001b[32minvolved in your wedding planning?\\n3. Have you identified any critical dependencies that should be considered?\\n4.\u001b[0m\n",
       "\u001b[32mWhat resources \u001b[0m\u001b[32m(\u001b[0m\u001b[32mvenues, budget, team members, etc.\u001b[0m\u001b[32m)\u001b[0m\u001b[32m are already available to you?\"\u001b[0m,\n",
       "    \u001b[33muser_message\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mis_followup\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[33mis_forward_permission\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33mis_permission_granted\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mis_outside_of_step\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33mplan_goal\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "    \u001b[33mplan_summary\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "    \u001b[33mplan_details\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mis_ready_to_move_forward\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33mis_summary_approved\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33minteraction_summary\u001b[0m=\u001b[32m''\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ChainStatus.PAUSE\n",
       "</pre>\n"
      ],
      "text/plain": [
       "ChainStatus.PAUSE\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">make_followup_questions\n",
       "</pre>\n"
      ],
      "text/plain": [
       "make_followup_questions\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plan_graph_state = PlannerState()\n",
    "graph = planner_graph(plan_graph_state, storage)\n",
    "graph.load_from_checkpoint(chain_id)\n",
    "\n",
    "graph.update_state_and_checkpoint({\"user_message\": \"I want to plan a wedding party\"})\n",
    "print(\"state_pre_checkpoint\")\n",
    "rprint(graph.state)\n",
    "\n",
    "plan_graph_state = PlannerState()\n",
    "graph = planner_graph(plan_graph_state, storage)\n",
    "graph.load_from_checkpoint(chain_id)\n",
    "\n",
    "await graph.resume_async()\n",
    "print(\"state_post_checkpoint\") \n",
    "rprint(graph.state)\n",
    "rprint(graph.chain_status)\n",
    "rprint(graph.next_execution_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PlannerState</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">version</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'44f1c3426cd72a291e94142dfe5e0c75'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">conversation</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Please state your goal in a single sentence.'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I want to plan a wedding party'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"To begin planning your wedding party, I need to gather some high-level information:\\n\\n1. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">What are the major components or phases you've identified for the wedding party? \\n2. Who are the key stakeholders </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">involved in your wedding planning?\\n3. Have you identified any critical dependencies that should be considered?\\n4.</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">What resources (venues, budget, team members, etc.) are already available to you?\"</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"I don't have any details in mind, please create a high level plan\"</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Here's a high-level plan for organizing a wedding party:\\n\\n1. **Venue Selection:** Choose </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">a location for the ceremony and reception that aligns with your vision and accommodates your guest count.\\n\\n2. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">**Guest List:** Create a list of guests to invite, considering the capacity of the venue and the budget.\\n\\n3. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">**Budget Planning:** Establish a comprehensive budget that covers all facets of the wedding, including venue, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">attire, catering, entertainment, and decorations.\\n\\n4. **Vendor Coordination:** Identify and hire vendors for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">catering, photography, music, flowers, and more. Build and maintain a strong relationship with each vendor.\\n\\n5. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">**Timeline Development:** Create a timeline that outlines all the key events and tasks from now until the wedding </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">day, ensuring smooth progress and on-time completion.\\n\\n6. **Legal Requirements:** Investigate and complete all </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">necessary legal paperwork, ensuring compliance with local marriage laws and customs.\\n\\n7. **Theme and Design:** </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Decide on a wedding theme and design elements, such as decor, color scheme, and personal attire.\\n\\n8. **Catering </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and Menu:** Plan the food and beverage offerings, considering guest preferences and dietary restrictions.\\n\\n9. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">**Logistics:** Organize transport, accommodation, and other logistics for guests, ensuring everyone arrives </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">conveniently and comfortably.\\n\\nWould you need more information on any specific component, or should we move on to</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the next phase?\"</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"This is good, let's move forward\"</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Great! We'll proceed to the next phase of planning. If you have any specific requirements </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">or need assistance with a particular part of the planning, feel free to let me know so that we can incorporate it </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">into the next planning stages.\"</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model_message</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Great! We'll proceed to the next phase of planning. If you have any specific requirements or </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">need assistance with a particular part of the planning, feel free to let me know so that we can incorporate it into</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the next planning stages.\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">user_message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_followup</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_forward_permission</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_permission_granted</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_outside_of_step</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_goal</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_summary</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">plan_details</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Venue Selection: Choosing a location for the wedding ceremony and reception.'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Guest List: Compiling a list of guests to be invited.'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Budget Planning: Setting a budget for the wedding and allocating funds to different components.'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Vendor Coordination: Selecting and managing vendors such as caterers, photographers, florists, and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">musicians.'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Timeline Development: Creating a schedule for the wedding day and tasks leading up to the event.'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Legal Requirements: Ensuring all necessary legal paperwork and permits are in place.'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Theme and Design: Deciding on a theme and design elements such as decor, color scheme, and attire.'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Catering and Menu: Planning the food and beverages to be served.'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'Logistics: Arranging transportation, accommodations, and other logistical details for guests and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">participants.'</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_ready_to_move_forward</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">is_summary_approved</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">interaction_summary</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mPlannerState\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mversion\u001b[0m=\u001b[32m'44f1c3426cd72a291e94142dfe5e0c75'\u001b[0m,\n",
       "    \u001b[33mconversation\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'Please state your goal in a single sentence.'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'user'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m'I want to plan a wedding party'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m,\n",
       "            \u001b[32m'content'\u001b[0m: \u001b[32m\"To begin planning your wedding party, I need to gather some high-level information:\\n\\n1. \u001b[0m\n",
       "\u001b[32mWhat are the major components or phases you've identified for the wedding party? \\n2. Who are the key stakeholders \u001b[0m\n",
       "\u001b[32minvolved in your wedding planning?\\n3. Have you identified any critical dependencies that should be considered?\\n4.\u001b[0m\n",
       "\u001b[32mWhat resources \u001b[0m\u001b[32m(\u001b[0m\u001b[32mvenues, budget, team members, etc.\u001b[0m\u001b[32m)\u001b[0m\u001b[32m are already available to you?\"\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'user'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m\"I don't have any details in mind, please create a high level plan\"\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m,\n",
       "            \u001b[32m'content'\u001b[0m: \u001b[32m\"Here's a high-level plan for organizing a wedding party:\\n\\n1. **Venue Selection:** Choose \u001b[0m\n",
       "\u001b[32ma location for the ceremony and reception that aligns with your vision and accommodates your guest count.\\n\\n2. \u001b[0m\n",
       "\u001b[32m**Guest List:** Create a list of guests to invite, considering the capacity of the venue and the budget.\\n\\n3. \u001b[0m\n",
       "\u001b[32m**Budget Planning:** Establish a comprehensive budget that covers all facets of the wedding, including venue, \u001b[0m\n",
       "\u001b[32mattire, catering, entertainment, and decorations.\\n\\n4. **Vendor Coordination:** Identify and hire vendors for \u001b[0m\n",
       "\u001b[32mcatering, photography, music, flowers, and more. Build and maintain a strong relationship with each vendor.\\n\\n5. \u001b[0m\n",
       "\u001b[32m**Timeline Development:** Create a timeline that outlines all the key events and tasks from now until the wedding \u001b[0m\n",
       "\u001b[32mday, ensuring smooth progress and on-time completion.\\n\\n6. **Legal Requirements:** Investigate and complete all \u001b[0m\n",
       "\u001b[32mnecessary legal paperwork, ensuring compliance with local marriage laws and customs.\\n\\n7. **Theme and Design:** \u001b[0m\n",
       "\u001b[32mDecide on a wedding theme and design elements, such as decor, color scheme, and personal attire.\\n\\n8. **Catering \u001b[0m\n",
       "\u001b[32mand Menu:** Plan the food and beverage offerings, considering guest preferences and dietary restrictions.\\n\\n9. \u001b[0m\n",
       "\u001b[32m**Logistics:** Organize transport, accommodation, and other logistics for guests, ensuring everyone arrives \u001b[0m\n",
       "\u001b[32mconveniently and comfortably.\\n\\nWould you need more information on any specific component, or should we move on to\u001b[0m\n",
       "\u001b[32mthe next phase?\"\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\u001b[32m'role'\u001b[0m: \u001b[32m'user'\u001b[0m, \u001b[32m'content'\u001b[0m: \u001b[32m\"This is good, let's move forward\"\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m,\n",
       "            \u001b[32m'content'\u001b[0m: \u001b[32m\"Great! We'll proceed to the next phase of planning. If you have any specific requirements \u001b[0m\n",
       "\u001b[32mor need assistance with a particular part of the planning, feel free to let me know so that we can incorporate it \u001b[0m\n",
       "\u001b[32minto the next planning stages.\"\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mmodel_message\u001b[0m=\u001b[32m\"Great\u001b[0m\u001b[32m! We'll proceed to the next phase of planning. If you have any specific requirements or \u001b[0m\n",
       "\u001b[32mneed assistance with a particular part of the planning, feel free to let me know so that we can incorporate it into\u001b[0m\n",
       "\u001b[32mthe next planning stages.\"\u001b[0m,\n",
       "    \u001b[33muser_message\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mis_followup\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33mis_forward_permission\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33mis_permission_granted\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[33mis_outside_of_step\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33mplan_goal\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "    \u001b[33mplan_summary\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "    \u001b[33mplan_details\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[32m'Venue Selection: Choosing a location for the wedding ceremony and reception.'\u001b[0m,\n",
       "        \u001b[32m'Guest List: Compiling a list of guests to be invited.'\u001b[0m,\n",
       "        \u001b[32m'Budget Planning: Setting a budget for the wedding and allocating funds to different components.'\u001b[0m,\n",
       "        \u001b[32m'Vendor Coordination: Selecting and managing vendors such as caterers, photographers, florists, and \u001b[0m\n",
       "\u001b[32mmusicians.'\u001b[0m,\n",
       "        \u001b[32m'Timeline Development: Creating a schedule for the wedding day and tasks leading up to the event.'\u001b[0m,\n",
       "        \u001b[32m'Legal Requirements: Ensuring all necessary legal paperwork and permits are in place.'\u001b[0m,\n",
       "        \u001b[32m'Theme and Design: Deciding on a theme and design elements such as decor, color scheme, and attire.'\u001b[0m,\n",
       "        \u001b[32m'Catering and Menu: Planning the food and beverages to be served.'\u001b[0m,\n",
       "        \u001b[32m'Logistics: Arranging transportation, accommodations, and other logistical details for guests and \u001b[0m\n",
       "\u001b[32mparticipants.'\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mis_ready_to_move_forward\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33mis_summary_approved\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "    \u001b[33minteraction_summary\u001b[0m=\u001b[32m''\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ChainStatus.DONE\n",
       "</pre>\n"
      ],
      "text/plain": [
       "ChainStatus.DONE\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">summarize_and_ask_permission\n",
       "</pre>\n"
      ],
      "text/plain": [
       "summarize_and_ask_permission\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plan_graph_state = PlannerState()\n",
    "graph = planner_graph(plan_graph_state, storage)\n",
    "graph.load_from_checkpoint(chain_id)\n",
    "\n",
    "graph.update_state_and_checkpoint({\"user_message\": \"This is good, let's move forward\"})\n",
    "\n",
    "plan_graph_state = PlannerState()\n",
    "graph = planner_graph(plan_graph_state, storage)\n",
    "graph.load_from_checkpoint(chain_id)\n",
    "\n",
    "await graph.resume_async()\n",
    "rprint(graph.state)\n",
    "rprint(graph.chain_status)\n",
    "rprint(graph.next_execution_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
