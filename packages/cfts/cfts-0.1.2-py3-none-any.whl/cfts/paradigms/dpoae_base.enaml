import logging
log = logging.getLogger(__name__)

from threading import Lock

import numpy as np

from atom.api import Event, Int, set_default, Str, Value

from enaml.application import deferred_call
from enaml.core.api import d_
from enaml.widgets.api import Container, DockItem, Label
from enaml.workbench.api import Extension

from psiaudio.pipeline import concat, coroutine
from psiaudio.util import tone_power_conv

from psi.context.api import (ContextGroup, ContextRow, EnumParameter,
                             Expression, Parameter, Result)
from psi.controller.api import (Blocked, Capture, ContinuousInput,
                                ControllerManifest, Discard, EpochOutput,
                                ExperimentAction, ExperimentEvent,
                                Input, Synchronized)

from psi.token.primitives import Cos2Envelope, Tone

from psi.data.sinks.api import EventLog, TableStore, BinaryStore


EXPERIMENT = __name__.rsplit('.', 1)[-1]


@coroutine
def process(n_time, n_fft, input, workbench, trial_widget, trials_widget,
            dpoae_acquired_cb, target, suffix=''):
    context = workbench.get_plugin('psi.context')
    controller = workbench.get_plugin('psi.controller')
    core = workbench.get_plugin('enaml.workbench.core')

    time_data = []
    fft_data = {}
    total_samples = 0
    n_trials = 0
    n_trial = 0
    ts_start = None

    while True:
        data = (yield)
        if data is Ellipsis:
            time_data = []
            fft_data = {}
            total_samples = 0
            n_trial = 0
            ts_start = None
            continue

        if ts_start is None:
            ts_start = data.s0 / data.fs
            metadata = data.metadata.copy()

        time_data.append(data)
        total_samples += data.shape[-1]
        n_trial += 1

        # Process acquired time segments once we have what we need
        if len(time_data) == n_time:
            mean_time = concat(time_data, axis='time')
            time_data = []

            f1 = context.get_value(f'primary{suffix}_tone_frequency')
            f2 = context.get_value(f'secondary{suffix}_tone_frequency')
            noise_floor = context.get_value('max_dpoae_noise_floor')
            dpoae = 2 * f1 - f2

            resolution = input.fs / mean_time.shape[-1]
            nf_frequencies = [f*resolution+dpoae for f in (-2, -1, 1, 2)]
            frequencies = [f1, f2, dpoae] + nf_frequencies

            rms = tone_power_conv(mean_time[0], input.fs, frequencies)
            level = input.calibration.get_db(frequencies, rms)
            nf_level = np.mean(level[3:])
            f1_level, f2_level, dpoae_level = level[:3]

            # If criterion met, store results
            if (nf_level < noise_floor) or (nf_level < dpoae_level):
                fft_data.setdefault('f1_level', []).append(f1_level)
                fft_data.setdefault('f2_level', []).append(f2_level)
                fft_data.setdefault('dpoae_level', []).append(dpoae_level)
                fft_data.setdefault('dpoae_noise_floor', []).append(nf_level)

                # Once we have n_fft, process results
                if len(fft_data['f1_level']) == n_fft:
                    for key in ('f1_level', 'f2_level', 'dpoae_level',
                                'dpoae_noise_floor'):
                        value = np.mean(fft_data[key])
                        context.set_value(key, value)

                    context.set_value('ts_end', ts_start + total_samples / input.fs)
                    context.set_value('ts_start', ts_start)

                    values = context.get_values()
                    values.update(metadata)
                    data = [values]
                    target(data)
                    fft_data = {}
                    ts_start = None
                    dpoae_acquired_cb({'data': data})
                    parameters = {'data': values}
                    n_trials += 1
                    core.invoke_command(f'dpoae{suffix}_store.save',
                                        parameters=parameters)
            else:
                log.debug(f'DPOAE{suffix} reject')

        # Post current status to the GUI
        def update_pb(n, widget):
            widget.value = n

        if trial_widget is not None:
            deferred_call(update_pb, n_trial, trial_widget)

        if trials_widget is not None:
            deferred_call(update_pb, n_trials, trials_widget)


class AnalyzeDPOAE(Input):

    n_fft = d_(Int(-1)).tag(metadata=True)
    n_time = d_(Int(-1)).tag(metadata=True)
    wb = d_(Value())
    trial_widget = d_(Value())
    trials_widget = d_(Value())
    suffix = d_(Str(''))
    dpoae_acquired = d_(Event())
    force_active = set_default(True)

    def dpoae_acquired_cb(self, event):
        self.dpoae_acquired = event

    def configure_callback(self):
        cb = super().configure_callback()
        return process(
            n_time=self.n_time,
            n_fft=self.n_fft,
            input=self,
            workbench=self.wb,
            trial_widget=self.trial_widget,
            trials_widget=self.trials_widget,
            dpoae_acquired_cb=self.dpoae_acquired_cb,
            target=cb,
            suffix=self.suffix,
        ).send


enamldef DPOAECapture(Capture): capture:
    # Begin capturing microphone signal once DPOAE starts. Linked
    # using an ExperimentAction.
    attr suffix = ''

    alias dpoae_acquired: analyze.dpoae_acquired

    Discard:
        # Discard the onset portion of the DPOAE
        name = f'discard{suffix}'
        duration << getattr(C, f'secondary{suffix}_tone_rise_time') * 4

        Blocked:
            # Duration (in seconds) of snippets to analyze
            name = f'segment{suffix}'
            duration << C.response_window

            AnalyzeDPOAE: analyze:
                name = f'analyze_dpoae{suffix}'
                wb = workbench
                n_fft = C.n_fft
                n_time = C.n_time
                suffix = capture.suffix
                trial_widget = workbench\
                    .get_plugin('enaml.workbench.ui')\
                    .window.find('dpoae_trial_pb')
                trials_widget = workbench\
                    .get_plugin('enaml.workbench.ui')\
                    .window.find('dpoae_trials_pb')


enamldef BaseDPOAEManifest(ControllerManifest): manifest:
    '''
    All subclasses must do the following:

        Define an experiment action that determines when the experiment is complete
    '''
    Extension:
        id = EXPERIMENT + '.sinks'
        point = 'psi.data.sinks'

        EventLog:
            show_widget = False

    Extension:
        id = 'tokens'
        point = 'psi.token.tokens'

        Cos2Envelope: tone:
            name = 'tone'
            label = 'tone'
            hide = ['start_time']
            Tone:
                hide = ['phase', 'polarity']

    Extension:
        id = EXPERIMENT + '.context'
        point = 'psi.context.items'

        ContextGroup:
            name = 'hardware_settings'
            label = 'Hardware'

        ContextGroup:
            name = 'result'
            label = 'Results'
            hide_when = 'always'

            Result:
                name = 'f2_spl'
                dtype = 'float64'

            Result:
                name = 'f1_spl'
                dtype = 'float64'

            Result:
                name = 'dpoae_spl'
                dtype = 'float64'

            Result:
                name = 'f2_noise_floor'
                dtype = 'float64'

            Result:
                name = 'f1_noise_floor'
                dtype = 'float64'

            Result:
                name = 'dpoae_noise_floor'
                dtype = 'float64'

            Result:
                name = 'ts_end'
                dtype = 'float64'

        ContextGroup:
            name = 'acquisition'
            label = 'DPOAE'

            Parameter:
                name = 'f2_frequency'
                label = 'F2 frequency'
                compact_label = 'F2'
                default = 8000

            Parameter:
                name = 'f2_level'
                label = 'F2 level'
                compact_label = 'L2'
                default = 80

            ContextRow:
                name = 'primary_settings'
                fmt = ['DPOAE', 'F2/F1 ratio', f2_f1_ratio, 'L1-L2 (dB)', l2_l1_diff, 'Noise floor (dB SPL)', nf]

                Parameter: f2_f1_ratio:
                    name = 'f2_f1_ratio'
                    label = 'F2/F1 ratio'
                    compact_label = 'F2/F1'
                    default = 1.2

                Parameter: l2_l1_diff:
                    name = 'l1_l2_difference'
                    label = 'L1-L2 (dB)'
                    compact_label = 'L1-L2'
                    default = 10

                Parameter: nf:
                    name = 'max_dpoae_noise_floor'
                    label = 'DPOAE noise floor (db SPL)'
                    compact_label = 'DPOAE NF'
                    dtype = 'float'
                    default = 0.0
                    scope = 'experiment'

            ContextRow:
                name = 'averaging_settings'
                fmt = ['Average', n_time, 'time and', n_fft, 'FFT epochs of', dur, 's duration']

                Parameter: n_fft:
                    name = 'n_fft'
                    label = 'Spectrum avg. (decr. variablity)'
                    compact_label = 'N FFT'
                    default = 8
                    scope = 'experiment'

                Parameter: n_time:
                    name = 'n_time'
                    label = 'Time avg. (decr. noise floor)'
                    compact_label = 'N time'
                    default = 16
                    scope = 'experiment'

                Parameter: dur:
                    name = 'response_window'
                    label = 'Response window (sec)'
                    compact_label = 'Resp. Window'
                    dtype = 'float'
                    default = 100e-3
                    scope = 'experiment'

    Extension:
        id = EXPERIMENT + '.actions'
        point = 'psi.controller.actions'

        ExperimentEvent:
            name = 'dpoae_acquired'

        # This action is mandatory and must be executed before any other
        # commands that require some information from context (including the
        # in-ear calibrqation mixins).
        ExperimentAction:
            event = 'experiment_initialize'
            command = 'psi.context.initialize'
            kwargs = {'selector': 'default', 'cycles': 1}

        # Once engines are configured, start the experiment!
        ExperimentAction:
            event = 'engines_configured'
            command = 'dpoae.start'
            kwargs = {'delay': 0.25}


enamldef SingleDPOAEManifest(BaseDPOAEManifest): manifest:

    Extension:
        id = EXPERIMENT + '.single_sinks'
        point = 'psi.data.sinks'

        BinaryStore:
            name = EXPERIMENT + '.zarr_store'
            continuous_inputs = ['system_microphone']

        TableStore:
            name = 'dpoae_store'

    Extension:
        id = EXPERIMENT + '.io'
        point = 'psi.controller.io'

        Synchronized:
            name = 'dpoae'

            EpochOutput: primary:
                name = 'primary'
                label = 'Primary'
                target_name = 'system_primary'
                configurable = False
                token = workbench.get_plugin('psi.token').get_token('tone')

            EpochOutput: secondary:
                name = 'secondary'
                label = 'Secondary'
                target_name = 'system_secondary'
                configurable = False
                token = workbench.get_plugin('psi.token').get_token('tone')

        DPOAECapture:
            source_name = 'system_microphone'
            name = 'dpoae_capture'
            start_event = 'dpoae_start'
            dpoae_acquired ::
                controller = workbench.get_plugin('psi.controller')
                controller.invoke_actions('dpoae_acquired', kw=change.get('value'))

    Extension:
        id = EXPERIMENT + '.single_context'
        point = 'psi.context.items'

        Expression:
            parameter = 'secondary_tone_frequency'
            expression = 'imul(f2_frequency, 1/response_window)'

        Expression:
            parameter = 'primary_tone_frequency'
            expression = 'imul(secondary_tone_frequency / f2_f1_ratio, 1/response_window)'

        Expression:
            parameter = 'secondary_tone_level'
            expression = 'f2_level'

        Expression:
            parameter = 'primary_tone_level'
            expression = 'f2_level + l1_l2_difference'

        Expression:
            parameter = 'primary_tone_duration'
            expression = 'secondary_tone_duration'

        Expression:
            parameter = 'secondary_tone_rise_time'
            expression = '25e-3'

        Expression:
            parameter = 'primary_tone_rise_time'
            expression = '25e-3'


def check_dpoae_status(manifest, workbench):
    with manifest.lock:
        if manifest.right_acquired is None:
            return
        if manifest.left_acquired is None:
            return
        controller = workbench.get_plugin('psi.controller')
        data = {'right': manifest.right_acquired, 'left': manifest.left_acquired}
        controller.invoke_actions('dpoae_acquired', kw=data)
        manifest.right_acquired = None
        manifest.left_acquired = None


enamldef DualDPOAEManifest(BaseDPOAEManifest): manifest:

    attr left_acquired = None
    attr right_acquired = None
    attr lock = Lock()

    Extension:
        id = EXPERIMENT + '.dual_sinks'
        point = 'psi.data.sinks'

        BinaryStore:
            name = EXPERIMENT + '.zarr_store'
            continuous_inputs = ['left_microphone', 'right_microphone']

        TableStore:
            name = 'dpoae_right_store'

        TableStore:
            name = 'dpoae_left_store'

    Extension:
        id = EXPERIMENT + '.dual_io'
        point = 'psi.controller.io'

        Synchronized:
            name = 'dpoae'

            EpochOutput:
                name = 'primary_left'
                label = 'Primary (left)'
                target_name = 'left_primary'
                configurable = False
                token = workbench.get_plugin('psi.token').get_token('tone')

            EpochOutput:
                name = 'secondary_left'
                label = 'Secondary (left)'
                target_name = 'left_secondary'
                configurable = False
                token = workbench.get_plugin('psi.token').get_token('tone')

            EpochOutput:
                name = 'primary_right'
                label = 'Primary (right)'
                target_name = 'right_primary'
                configurable = False
                token = workbench.get_plugin('psi.token').get_token('tone')

            EpochOutput:
                name = 'secondary_right'
                label = 'Secondary (right)'
                target_name = 'right_secondary'
                configurable = False
                token = workbench.get_plugin('psi.token').get_token('tone')

        DPOAECapture:
            source_name = 'right_microphone'
            name = 'right_dpoae_capture'
            start_event = 'dpoae_start'
            suffix = '_right'
            dpoae_acquired ::
                log.info('Right DPOAE acquired')
                manifest.right_acquired = change.get('value')
                check_dpoae_status(manifest, workbench)

        DPOAECapture:
            source_name = 'left_microphone'
            name = 'left_dpoae_capture'
            start_event = 'dpoae_start'
            suffix = '_left'
            dpoae_acquired ::
                log.info('Left DPOAE acquired')
                manifest.left_acquired = change.get('value')
                check_dpoae_status(manifest, workbench)

    Extension:
        id = EXPERIMENT + '.dual_context'
        point = 'psi.context.items'

        Expression:
            parameter = 'secondary_left_tone_frequency'
            expression = 'imul(f2_frequency, 1/response_window)'

        Expression:
            parameter = 'primary_left_tone_frequency'
            expression = 'imul(secondary_left_tone_frequency / f2_f1_ratio, 1/response_window)'

        Expression:
            parameter = 'secondary_left_tone_level'
            expression = 'f2_level'

        Expression:
            parameter = 'primary_left_tone_level'
            expression = 'f2_level + l1_l2_difference'

        Expression:
            parameter = 'primary_left_tone_duration'
            expression = 'secondary_left_tone_duration'

        Expression:
            parameter = 'secondary_left_tone_rise_time'
            expression = '25e-3'

        Expression:
            parameter = 'primary_left_tone_rise_time'
            expression = '25e-3'

        Expression:
            parameter = 'secondary_right_tone_frequency'
            expression = 'imul(f2_frequency, 1/response_window)'

        Expression:
            parameter = 'primary_right_tone_frequency'
            expression = 'imul(secondary_right_tone_frequency / f2_f1_ratio, 1/response_window)'

        Expression:
            parameter = 'secondary_right_tone_level'
            expression = 'f2_level'

        Expression:
            parameter = 'primary_right_tone_level'
            expression = 'f2_level + l1_l2_difference'

        Expression:
            parameter = 'primary_right_tone_duration'
            expression = 'secondary_right_tone_duration'

        Expression:
            parameter = 'secondary_right_tone_rise_time'
            expression = '25e-3'

        Expression:
            parameter = 'primary_right_tone_rise_time'
            expression = '25e-3'
