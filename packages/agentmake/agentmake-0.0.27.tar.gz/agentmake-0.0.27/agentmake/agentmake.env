# Backend: anthropic
ANTHROPIC_API_KEY= # required
ANTHROPIC_MODEL=claude-3-5-sonnet-latest # optional
ANTHROPIC_TEMPERATURE=0.3 # optional
ANTHROPIC_MAX_TOKENS=8192 # optional

# Backend: azure
AZURE_API_KEY= # required
AZURE_API_ENDPOINT= # required
AZURE_API_VERSION=2024-10-21 # optional
AZURE_MODEL=gpt-4o # optional
AZURE_TEMPERATURE=0.3 # optional
AZURE_MAX_TOKENS=16384 # optional

# Backend: cohere
COHERE_API_KEY= # required
COHERE_MODEL=command-r-plus # optional
COHERE_TEMPERATURE=0.3 # optional
COHERE_MAX_TOKENS=4000 # optional

# Backend: custom
CUSTOM_API_KEY= # required
CUSTOM_API_ENDPOINT= # required
CUSTOM_MODEL= # required
CUSTOM_TEMPERATURE=0.3 # optional
CUSTOM_MAX_TOKENS=4000 # optional

# Backend: deepseek
DEEPSEEK_API_KEY= # required
DEEPSEEK_MODEL=deepseek-chat # optional
DEEPSEEK_TEMPERATURE = 0.3 # optional
DEEPSEEK_MAX_TOKENS = 8000 # optional

# Backend: github
GITHUB_API_KEY= # required
GITHUB_MODEL=gpt-4o # optional
GITHUB_TEMPERATURE=0.3 # optional
GITHUB_MAX_TOKENS=4000 # optional

# Backend: googleai
GOOGLEAI_API_KEY=${GEMINI_API_KEY} # required
GOOGLEAI_MODEL=gemini-1.5-pro # optional
GOOGLEAI_TEMPERATURE=0.3 # optional
GOOGLEAI_MAX_TOKENS=8192 # optional

# Backend: vertexai
VERTEXAI_API_KEY=${GOOGLE_APPLICATION_CREDENTIALS} # required
VERTEXAI_API_PROJECT_ID= # required
VERTEXAI_API_SERVICE_LOCATION=us-central1 # optional
VERTEXAI_MODEL=gemini-1.5-pro # optional
VERTEXAI_TEMPERATURE=0.3 # optional
VERTEXAI_MAX_TOKENS=8192 # optional

# Backend: groq
GROQ_API_KEY= # required
GROQ_MODEL=llama-3.3-70b-versatile # optional
GROQ_TEMPERATURE=0.3 # optional
GROQ_MAX_TOKENS=32768 # optional

# Backend: llamacpp
LLAMACPP_API_ENDPOINT=http://127.0.0.1:8080/v1 # optional
LLAMACPP_TEMPERATURE=0.3 # optional
LLAMACPP_MAX_TOKENS=2048 # optional

# Backend: mistral
MISTRAL_API_KEY= # required
MISTRAL_MODEL=mistral-large-latest # optional
MISTRAL_TEMPERATURE=0.3 # optional
MISTRAL_MAX_TOKENS=8000 # optional

# Backend: ollama
OLLAMA_ENDPOINT= # optional
OLLAMA_MODEL=llama3.2 # optional
OLLAMA_TEMPERATURE=0.3 # optional
OLLAMA_MAX_TOKENS=-1 # optional
OLLAMA_CONTEXT_WINDOW=2048 # optional
OLLAMA_BATCH_SIZE=512 # optional
OLLAMA_KEEP_ALIVE=5m # optional

# Backend: openai
OPENAI_API_KEY= # required
OPENAI_MODEL=gpt-4o # optional
OPENAI_TEMPERATURE=0.3 # optional
OPENAI_MAX_TOKENS=16384 # optional

# Backend: xai
XAI_API_KEY= # required
XAI_MODEL=grok-2-latest # optional
XAI_TEMPERATURE=0.3 # optional
XAI_MAX_TOKENS=127999 # optional
