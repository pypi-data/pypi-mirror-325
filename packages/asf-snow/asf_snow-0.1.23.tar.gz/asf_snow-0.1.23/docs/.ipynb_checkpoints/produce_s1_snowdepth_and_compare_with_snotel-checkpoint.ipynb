{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8f9ba17-9bd8-4753-8372-6afdc2411a1c",
   "metadata": {},
   "source": [
    "This notebook demostrates the work flow of producing S1 snow depth and comparing them with the SNOTEL observations. S1 snow depth is calculated by spicy-snow package [https://github.com/SnowEx/spicy-snow] SNOTEL data are obtained from the [https://wcc.sc.egov.usda.gov/reportGenerator/]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d322fe-6ac8-44c1-8504-3ebeba7f45e5",
   "metadata": {},
   "source": [
    "The work flow have three steps. 1. download SNOTEL data, 2. produce S1 snow depth data, 3. calculate the statistic, 4. display the comparison results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd862ad-c3b5-4896-a22d-0950974fd95d",
   "metadata": {},
   "source": [
    "# 0. prepare jupyter notebook running environment\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef07425e-abd4-4b01-becc-4bcf74e0e136",
   "metadata": {},
   "source": [
    "## 0.1 Download the asf-snow package and create the asf-snow conda environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5fe756-86e1-4221-ab36-52a1b04b753c",
   "metadata": {},
   "source": [
    "%%bash\n",
    "\n",
    "Method 1:\n",
    "\n",
    "git clone https://github.com/asfadmin/asf-snow.git\n",
    "cd asf-snow\n",
    "mamba env create -f environment.yml\n",
    "conda activate asf-snow\n",
    "python -m pip install .\n",
    "\n",
    "Method 2:\n",
    "\n",
    "mamba create -n asf-snow python=3.12.7\n",
    "conda activate asf-snow\n",
    "python -m pip install asf-snow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc84b09-11c5-45cb-b4b5-5e55a94e330f",
   "metadata": {},
   "source": [
    "## 0.2 Start your jupyter notebook and run it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb18984-4bd9-4bfb-9a5a-8e499f6ee3c4",
   "metadata": {},
   "source": [
    "start jupyter notebook service by command \"jupyter notebook\"\n",
    "click \"Kernel\" item in the menu, choose \"asf-snow-kernel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7118458-bd05-451b-8e9e-4307d909acae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import netrc\n",
    "\n",
    "from asf_snow.utils.snotel import download_snotel\n",
    "\n",
    "from asf_snow.sentinel1_snow import *\n",
    "\n",
    "from asf_snow.utils.analyze_sentinel1_snow import bbox_via_point\n",
    "\n",
    "from asf_snow.utils.s1_snotel_corr_ts import *\n",
    "\n",
    "from asf_snow.utils.utils import read_environment, write_environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04539df0-9a07-4f40-a0bc-c15113d46a5f",
   "metadata": {},
   "source": [
    "# 1. Downalod the SNOTEL data\n",
    "Input work directory, SNOTEL site, and date range, output snotel geodatafram and save it to snotelfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e8626b-fdd7-48a2-9a96-7bb9f6f4e4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up input arguments workdir, snotelsite, datarange\n",
    "envt = {\"workdir\":'/media/jiangzhu/Elements/crrel/SNOTEL/creamers/20230801_20240731',\n",
    "                \"snotelsite\": \"1302:AK:SNTL\",\n",
    "                \"daterange\": ['2023-08-01', '2024-07-31']\n",
    "              }\n",
    "\n",
    "site_and_range = f'{envt['snotelsite'].replace(\":\",\"_\")}_{envt['daterange'][0].replace(\"-\",\"\")}_{envt['daterange'][1].replace(\"-\",\"\")}.geojson'\n",
    "snotelfile = Path.joinpath(Path(envt['workdir']), site_and_range)\n",
    "\n",
    "# download SNOTEL data\n",
    "snotelfile, snotel = download_snotel(snotelsite=envt['snotelsite'], stdate=envt['daterange'][0], eddate=envt['daterange'][1], snotelfile=snotelfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c354a45-b8bb-46ea-b5c0-4cd93189b286",
   "metadata": {},
   "source": [
    "# 2. Produce S1 snow Depth\n",
    "input username, password, flightdir, jobname, existjobname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e9a388-8a04-4438-9a12-8ce1b9ab805e",
   "metadata": {},
   "source": [
    "## 2.1 Calulate the square centered at SNOTEL site\n",
    "Input the resolution of the AOI, output is bbox=[minlon,minlat, maxlon,maxlat. The bbox is uased to produce the S1 snow depth product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366b87db-7894-4919-af45-d2fb1426c017",
   "metadata": {},
   "outputs": [],
   "source": [
    "envt['snotelres'] = 10000.0  # unit meter,\n",
    "sitelon = float(snotel.iloc[0]['geometry'].x)\n",
    "sitelat = float(snotel.iloc[0]['geometry'].y)\n",
    "bbox = bbox_via_point(sitelon, sitelat, envt['snotelres'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f973d9-3ea5-4573-bc41-976e2a874346",
   "metadata": {},
   "source": [
    "## 2.2 Define the input for producing S1 snow depth\n",
    "Inputs: usename, password, jobname, existjobname for creating hyp3 RTC product, flight direction to choose for calculateing the snow depth.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ea8388-d988-44de-a130-8bb4b7b0bcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "envt['flightdir'] = 'descending' # one of ascending, descending, both\n",
    "envt['jobname'] = 'jz_creamers_20230801_20240731_10k'\n",
    "envt['existjobname'] = 'jz_creamers_20230801_20240731_10k'\n",
    "envt['method'] = 'adjfcf' #standard, vvonly, crvv, adjfcf, default is standard\n",
    "envt['parameterabc'] = [0.1, 0.5, 0.55, 1.0, 1.0] # [A, B, C, ll, ul], default is [2.5, 0.2, 0.55, 0.0, 1.0]\n",
    "envt['wet_snow_thresh'] = -3.0\n",
    "username=None # User can input the username and password for Earthdata login, If not, you can save the username and password in .netrc file\n",
    "password=None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c813fae2-c165-481a-842b-b2c0ff7e801f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# username= input(\"Enter your EARTHDATA_USERNAME:\")\n",
    "# password = input(\"Enter your EARTHDATA_PASSWORD:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7836eb58-2dc7-4c64-828c-f0dfa8eb0afd",
   "metadata": {},
   "source": [
    "## 2.3 Run process to get the S1 snow depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb500f73-5419-47d8-9810-cca84dba4758",
   "metadata": {},
   "outputs": [],
   "source": [
    "site_and_range = f'{envt['flightdir']}/sentinel1_{envt['method']}_A{envt['parameterabc'][0]}_B{envt['parameterabc'][1]}_C{envt['parameterabc'][2]}_{envt['snotelsite'].replace(\":\",\"_\")}_{int(envt['snotelres'])}_{envt['daterange'][0].replace(\"-\",\"\")}_{envt['daterange'][1].replace(\"-\",\"\")}_{envt['flightdir']}.nc'\n",
    "\n",
    "nc_file = Path(envt['workdir']).joinpath(site_and_range)\n",
    "\n",
    "nc_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "envt_jsonfile = f'{envt['workdir']}/tmp/environment.json'\n",
    "envt['area'] = bbox\n",
    "envt['step'] = 'begin'\n",
    "if not os.path.exists(envt_jsonfile):\n",
    "    os.environ['ENVIRONMENT'] = json.dumps(envt)\n",
    "else:\n",
    "    prev_envt = utils.read_environment(envt_jsonfile)\n",
    "    os.environ['ENVIRONMENT'] = json.dumps(prev_envt)\n",
    "    # envt['step'] = prev_envt['step']\n",
    "\n",
    "# set environment for share\n",
    "if  username and password:\n",
    "    os.environ['EARTHDATA_USERNAME'] = username\n",
    "    os.environ['EARTHDATA_PASSWORD'] = password\n",
    "else:\n",
    "    try:\n",
    "        secrets = netrc.netrc()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: .netrc file not found in {os.path.expanduser('~')}\")\n",
    "    except netrc.NetrcParseError as e:\n",
    "        print(f\"Error parsing .netrc: {e}\")\n",
    "    else:\n",
    "        username, _, password = secrets.hosts['urs.earthdata.nasa.gov']\n",
    "        os.environ['EARTHDATA_USERNAME'] = username\n",
    "        os.environ['EARTHDATA_PASSWORD'] = password\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d5b4d5-6a8a-4559-b0e3-f7c83517c6f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not Path(nc_file).exists():\n",
    "    # create S1 snow depth file and return the xarraydataset\n",
    "    nc_ds = sentinel1_snow(area=bbox, dates=envt['daterange'], flightdir=envt['flightdir'], workdir=envt['workdir'],\n",
    "           jobname=envt['jobname'], existjobname=envt['existjobname'], outnc=nc_file, method=envt['method'],\n",
    "           parameterabc=envt['parameterabc'], wet_snow_thresh=envt['wet_snow_thresh'])\n",
    "\n",
    "    # update envt and save it as environment file\n",
    "    os_env = json.loads(os.environ['ENVIRONMENT'])\n",
    "    envt['step'] = os_env['step']\n",
    "    write_environment(envt, f'{envt['workdir']}/tmp/environment.json')\n",
    "\n",
    "else:\n",
    "    # to_netcdf and read it back, the coords variables change, and crs is missing, need to restore them back\n",
    "    nc_ds = xr.open_dataset(nc_file)\n",
    "\n",
    "# set crs to nc_ds as needed\n",
    "try:\n",
    "    crs = nc_ds.rio.crs\n",
    "except:\n",
    "    try:\n",
    "        nc_ds = nc_ds.set_coords((\"spatial_ref\",\"projection\"))\n",
    "        nc_ds.rio.write_crs('epsg:4326', inplace=True)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e065af7-9d0e-470b-94b1-913cc527b408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add some attrs to the xarray.dataset\n",
    "nc_ds.attrs['sitelon'] = sitelon\n",
    "nc_ds.attrs['sitelat'] = sitelat\n",
    "nc_ds.attrs['orbit'] = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d702d4f6-c7cd-4e21-9670-353041db3c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the bounds of nc_ds into geojson file\n",
    "s1_poly = bbox2polygon(list(nc_ds.snow_depth.rio.bounds()))\n",
    "geojson_file = str(nc_file).replace(\".nc\", \".geojson\")\n",
    "write_polygon(s1_poly, geojson_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb31fe5-b7d4-4666-8be2-d69937e28f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "geojson_file = str(nc_file).replace(\".nc\", \".geojson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426e8fd2-3a0a-401b-94ba-62a343556616",
   "metadata": {},
   "source": [
    "# 3. Compare S1 snow depth with SNOTEL data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b3763d-9f14-4724-82ee-002b9b030d6b",
   "metadata": {},
   "source": [
    "## 3.1 Inputs for the correlation\n",
    "inputs: \n",
    "The longitude and latitude of the pixel of interest (POI) that you want to investigate,\n",
    "avg (True/False) determines if you want to compare the average of pixles within the square centered at the POI or the POI with SNOTEL data,\n",
    "res is the length of square in meter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79468f8-561f-4aed-951f-d77aa0804c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "poi = {'pixel3': [-147.7175, 64.8383]} #user input the name and logitude and latitude of the POI or the center of the AOI\n",
    "envt['avg']=True   #if you want to compare the average of AOI to SNOTEL, set True, if you want to compare the POI with SNOITEL, set False\n",
    "envt['res']=1000.0 # the length of side of the squaral AOI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176f5e71-c53f-456a-904e-5488f46c05fe",
   "metadata": {},
   "source": [
    "## 3.2 Obtain the shapefile of the sqaure and clip the S1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e7a280-ea43-4d81-b643-6f8d04c095a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = list(poi.keys())[0]\n",
    "geojson_file_pixel = geojson_file.replace(\".geojson\", f'_{key}.geojson')\n",
    "\n",
    "if envt['avg'] and envt['res']:\n",
    "    poly = polygon_via_point(lon=poi[key][0], lat=poi[key][1], resolution=envt['res'])\n",
    "    jsstr = to_geojson(poly)\n",
    "    geometries = [json.loads(jsstr)]\n",
    "    nc_ds_pixel = nc_ds.rio.clip(geometries, all_touched=True)\n",
    "    \n",
    "    # write boundary as polygon\n",
    "    s1_poly_clipped = bbox2polygon(list(nc_ds_pixel.snow_depth.rio.bounds()))\n",
    "    \n",
    "    write_polygon(s1_poly_clipped, geojson_file_pixel)\n",
    "else:\n",
    "    nc_ds_pixel = nc_ds.copy(deep=True)\n",
    "\n",
    "nc_ds_pixel.attrs['lon'] = poi[key][0]\n",
    "nc_ds_pixel.attrs['lat'] = poi[key][1]\n",
    "nc_ds_pixel.attrs['poi'] = key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0394b7f2-d58e-4a01-961b-374ac9387021",
   "metadata": {},
   "source": [
    "### Calculate the R, MEAN, and STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac3d1b4-5666-4f62-89df-a3e34c79da0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get x and y of poi in the clipped S1 data\n",
    "gt = get_gt(nc_ds_pixel)\n",
    "x, y = lonlat_to_colrow(gt, poi[key][0], poi[key][1])\n",
    "\n",
    "# Calculate the R, mean, ans std within the time range from st_mmdd to ed_mmdd\n",
    "snowcover = calc_s1_snotel_correlation(nc_ds_pixel, snotel, st_mmdd='11-01', ed_mmdd='04-01')\n",
    "\n",
    "# save the clipped S1 data with statistic associated\n",
    "outfile = geojson_file_pixel.replace(\".geojson\", \".nc\")\n",
    "write_to_netcdf(snowcover, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb6b6bb-cb64-47d1-8ab1-e497f0a2ef69",
   "metadata": {},
   "source": [
    "# 4. Display the comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58b79ce-e6cf-439b-8fe3-1e22b30dfbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if envt['avg']:\n",
    "    pngfile = geojson_file_pixel.replace(\".geojson\", f'_{int(envt['res'])}_{key}_{poi[key][0]}_{poi[key][1]}.png')\n",
    "else:\n",
    "    pngfile = geojson_file_pixel.replace(\".geojson\", f'_{key}_{poi[key][0]}_{poi[key][1]}.png')\n",
    "\n",
    "draw_lines(nc_ds_pixel, snotel, outfile=pngfile, y=y, x=x, average=envt['avg'], res=envt['res'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66366f4d-73e8-40a5-aea3-38fca1ab05ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('completed...')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asf-snow-kernel",
   "language": "python",
   "name": "asf-snow-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
