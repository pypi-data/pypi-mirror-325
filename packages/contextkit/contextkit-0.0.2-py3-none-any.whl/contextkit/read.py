"""Read X for llm context"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00_read.ipynb.

# %% auto 0
__all__ = ['read_url', 'read_gist', 'read_gh_file', 'read_file', 'is_unicode', 'read_dir', 'read_pdf', 'read_yt_transcript',
           'read_google_sheet', 'read_gdoc']

# %% ../nbs/00_read.ipynb 5
import httpx 
import html2text
from fastcore.all import delegates, ifnone

import re, os, glob, string
import requests
import fnmatch, mimetypes

from PyPDF2 import PdfReader
from toolslm.download import html2md, read_html

# %% ../nbs/00_read.ipynb 8
def read_url(url,           # URL to read
             heavy=False,   # Use headless browser
             sel=None,      # Css selector to pull content from
             useJina=False, # Use Jina for the markdown conversion
             **kwargs): 
    "Reads a url and converts to markdown"
    if not heavy and not useJina: return read_html(url,sel=sel,**kwargs)
    elif not heavy and useJina:   return httpx.get(f"https://r.jina.ai/{url}").text
    elif heavy and not useJina: 
        import playwrightnb
        return playwrightnb.url2md(url,sel=ifnone(sel,'body'), **kwargs)
    elif heavy and useJina: raise NotImplementedError("Unsupported. No benefit to using Jina with playwrightnb")


# %% ../nbs/00_read.ipynb 16
def read_gist(url):
    "Returns raw gist content, or None"
    pattern = r'https://gist\.github\.com/([^/]+)/([^/]+)'
    match = re.match(pattern, url)
    if match:
        user, gist_id = match.groups()
        raw_url = f'https://gist.githubusercontent.com/{user}/{gist_id}/raw'
        return httpx.get(raw_url).text
    else:
        return None

# %% ../nbs/00_read.ipynb 20
def read_gh_file(url):
    "Reads the contents of a file from its GitHub URL"
    pattern = r'https://github\.com/([^/]+)/([^/]+)/blob/([^/]+)/(.+)'
    replacement = r'https://raw.githubusercontent.com/\1/\2/refs/heads/\3/\4'
    raw_url = re.sub(pattern, replacement, url)
    return httpx.get(raw_url).text

# %% ../nbs/00_read.ipynb 24
def read_file(path): return open(path,'r').read()

# %% ../nbs/00_read.ipynb 25
def is_unicode(filepath, sample_size=1024):
    try:
        with open(filepath, 'r') as file: sample = file.read(sample_size)
        return True
    except UnicodeDecodeError:
        return False

# %% ../nbs/00_read.ipynb 28
def read_dir(path,                          # path to read
             unicode_only=True,             # ignore non-unicode files
             included_patterns=["*"],       # glob pattern of files to include
             excluded_patterns=[".git/**"], # glob pattern of files to exclude
             verbose=True,                  # log paths of files being read
             as_dict=False                  # returns dict of {path,content}
            ) -> str|dict:                  # returns string with contents of files read
    pattern = '**/*'
    result = {}
    for file_path in glob.glob(os.path.join(path, pattern), recursive=True):
        if any(fnmatch.fnmatch(file_path, pat) for pat in excluded_patterns):
            continue
        if not any(fnmatch.fnmatch(file_path, pat) for pat in included_patterns):
            continue
        if os.path.isfile(file_path):
            if unicode_only and not is_unicode(file_path):
                continue
            if verbose:
                print(f"Including {file_path}")
            with open(file_path, 'r', errors='ignore') as f:
                result[file_path] = f.read()
    if not as_dict:
        return '\n'.join([f"--- File: {file_path} ---\n{v}\n--- End of {file_path} ---" for file_path,v in result.items()])
    else:
        return result

# %% ../nbs/00_read.ipynb 31
def read_pdf(file_path: str) -> str:
    with open(file_path, 'rb') as file:
        reader = PdfReader(file)
        return ' '.join(page.extract_text() for page in reader.pages)

# %% ../nbs/00_read.ipynb 34
def read_yt_transcript(yt_url):
    from pytube import YouTube
    from youtube_transcript_api import YouTubeTranscriptApi
    try:
        yt = YouTube(yt_url)
        video_id = yt.video_id
    except Exception as e:
        print(f"An error occurred parsing yt urul: {e}")
        return None
    transcript = YouTubeTranscriptApi.get_transcript(video_id)
    return ' '.join(entry['text'] for entry in transcript) 

# %% ../nbs/00_read.ipynb 37
def read_google_sheet(url):
    sheet_id = url.split('/d/')[1].split('/')[0]
    csv_url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv&id={sheet_id}&gid=0'
    res = requests.get(url=csv_url)
    return res.content

# %% ../nbs/00_read.ipynb 42
def read_gdoc(url):
    import html2text
    doc_url = url
    doc_id = doc_url.split('/d/')[1].split('/')[0]
    export_url = f'https://docs.google.com/document/d/{doc_id}/export?format=html'
    html_doc_content = requests.get(export_url).text
    doc_content = html2text.html2text(html_doc_content)
    return doc_content
