{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN4uSmsdFPdwP1pTHizEntn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qubvel/rt-pose/blob/main/notebooks/video_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "DNmiA3rS1D2G"
      },
      "outputs": [],
      "source": [
        "# !pip install -U pip uv\n",
        "# !pip install -U git+https://github.com/qubvel/rt-pose.git\n",
        "# !uv pip install --system \"moviepy==2.*\" supervision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import moviepy\n",
        "import argparse\n",
        "import numpy as np\n",
        "import supervision as sv\n",
        "import huggingface_hub\n",
        "\n",
        "from tqdm import tqdm\n",
        "from rt_pose import PoseEstimationPipeline, PoseEstimationOutput"
      ],
      "metadata": {
        "id": "56xk9I88MWs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\"\n",
        "\n",
        "capability = torch.cuda.get_device_capability(device)\n",
        "dtype = torch.bfloat16 if capability > (8, 0) else torch.float16\n",
        "\n",
        "print(f\"Using device: {device}\")\n",
        "print(f\"Using dtype: {dtype}\")"
      ],
      "metadata": {
        "id": "ouNQ66DwX8EX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pose estimation pipeline\n",
        "pipeline = PoseEstimationPipeline(\n",
        "    object_detection_checkpoint=\"PekingU/rtdetr_r34vd\",\n",
        "    pose_estimation_checkpoint=\"usyd-community/vitpose-plus-small\",\n",
        "    device=\"cuda\",\n",
        "    dtype=torch.float16,\n",
        "    compile=True,  # True to get more speedup\n",
        ")"
      ],
      "metadata": {
        "id": "vohX_wue1ZK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# As you can see from logs below, model compilation is pretty long step.\n",
        "# Compilation happens just-in-time, that is why we use warmup, to pass\n",
        "# a few batches to the models to compile them.\n",
        "pipeline.warmup()"
      ],
      "metadata": {
        "id": "RNsmES_3N7QN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining some useful functions and loading demo clip"
      ],
      "metadata": {
        "id": "C_es59-vZWcp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "def show_clip(path):\n",
        "    with open(path, \"rb\") as f:\n",
        "        mp4 = f.read()\n",
        "    data = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "    return HTML(f'<video width=400 controls><source src={data} type=\"video/mp4\"></video>')\n",
        "\n",
        "def visualize_output(image: np.ndarray, output: PoseEstimationOutput, confidence: float = 0.3) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Visualize pose estimation output.\n",
        "    \"\"\"\n",
        "    keypoints_xy = output.keypoints_xy.float().cpu().numpy()\n",
        "    scores = output.scores.float().cpu().numpy()\n",
        "\n",
        "    # Supervision will not draw vertices with `0` score\n",
        "    # and coordinates with `(0, 0)` value\n",
        "    invisible_keypoints = scores < confidence\n",
        "    scores[invisible_keypoints] = 0\n",
        "    keypoints_xy[invisible_keypoints] = 0\n",
        "\n",
        "    keypoints = sv.KeyPoints(xy=keypoints_xy, confidence=scores)\n",
        "\n",
        "    _, y_min, _, y_max = output.person_boxes_xyxy.T\n",
        "    height = int((y_max - y_min).mean().item())\n",
        "    radius = max(height // 100, 4)\n",
        "    thickness = max(height // 200, 3)\n",
        "    edge_annotator = sv.EdgeAnnotator(color=sv.Color.YELLOW, thickness=thickness)\n",
        "    vertex_annotator = sv.VertexAnnotator(color=sv.Color.ROBOFLOW, radius=radius)\n",
        "\n",
        "    annotated_frame = image.copy()\n",
        "    annotated_frame = edge_annotator.annotate(annotated_frame, keypoints)\n",
        "    annotated_frame = vertex_annotator.annotate(annotated_frame, keypoints)\n",
        "\n",
        "    return annotated_frame"
      ],
      "metadata": {
        "id": "XeZ9ay6-1-n-"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load demo clip from dataset, but you can use a local one\n",
        "path = huggingface_hub.hf_hub_download(\n",
        "    repo_id=\"qubvel-hf/assets\", filename=\"rt_pose_break_dance_v1.mp4\", repo_type=\"dataset\"\n",
        ")\n",
        "clip = moviepy.VideoFileClip(path)"
      ],
      "metadata": {
        "id": "FNpmzN4Y3UmD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30f81025-8e72-44c7-dafd-a159cd209fa6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'video_found': True, 'audio_found': True, 'metadata': {'major_brand': 'isom', 'minor_version': '512', 'compatible_brands': 'isomiso2avc1mp41', 'comment': 'vid:v12044gd0000cqrtpdfog65mut9h0ba0', 'aigc_info': '{\"aigc_label_type\": 0}', 'encoder': 'Lavf58.76.100'}, 'inputs': [{'streams': [{'input_number': 0, 'stream_number': 0, 'stream_type': 'video', 'language': None, 'default': True, 'size': [576, 1024], 'bitrate': 1076, 'fps': 59.63, 'codec_name': 'h264', 'profile': '(High)', 'metadata': {'Metadata': '', 'handler_name': 'VideoHandler', 'vendor_id': '[0][0][0][0]'}}, {'input_number': 0, 'stream_number': 1, 'stream_type': 'audio', 'language': None, 'default': True, 'fps': 44100, 'bitrate': 32, 'metadata': {'Metadata': '', 'handler_name': 'SoundHandler', 'vendor_id': '[0][0][0][0]'}}], 'input_number': 0}], 'duration': 12.95, 'bitrate': 1118, 'start': 0.0, 'default_video_input_number': 0, 'default_video_stream_number': 0, 'video_codec_name': 'h264', 'video_profile': '(High)', 'video_size': [576, 1024], 'video_bitrate': 1076, 'video_fps': 59.63, 'default_audio_input_number': 0, 'default_audio_stream_number': 1, 'audio_fps': 44100, 'audio_bitrate': 32, 'video_duration': 12.95, 'video_n_frames': 772}\n",
            "/usr/local/lib/python3.11/dist-packages/imageio_ffmpeg/binaries/ffmpeg-linux-x86_64-v7.0.2 -i /root/.cache/huggingface/hub/datasets--qubvel-hf--assets/snapshots/da3d6849ff7f73270abee0bcf01339a902c8d9a8/rt_pose_break_dance_v1.mp4 -loglevel error -f image2pipe -vf scale=576:1024 -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment next line to show annotated clip\n",
        "# show_clip(path)"
      ],
      "metadata": {
        "id": "ShcqAfMRS6Ns"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running pose estimation pipeline"
      ],
      "metadata": {
        "id": "kPK6-d1SZJxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "annotated_frames = []\n",
        "frames = list(clip.iter_frames())\n",
        "\n",
        "for frame in tqdm(frames, total=clip.n_frames):\n",
        "    output = pipeline(frame)\n",
        "    annotated_frame = visualize_output(frame, output, confidence=0.3)\n",
        "    annotated_frames.append(annotated_frame)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8bb3GL-NOnx",
        "outputId": "6ecb8d31-3a0b-465a-bde4-91ca10851f0c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'video_found': True, 'audio_found': True, 'metadata': {'major_brand': 'isom', 'minor_version': '512', 'compatible_brands': 'isomiso2avc1mp41', 'comment': 'vid:v12044gd0000cqrtpdfog65mut9h0ba0', 'aigc_info': '{\"aigc_label_type\": 0}', 'encoder': 'Lavf58.76.100'}, 'inputs': [{'streams': [{'input_number': 0, 'stream_number': 0, 'stream_type': 'video', 'language': None, 'default': True, 'size': [576, 1024], 'bitrate': 1076, 'fps': 59.63, 'codec_name': 'h264', 'profile': '(High)', 'metadata': {'Metadata': '', 'handler_name': 'VideoHandler', 'vendor_id': '[0][0][0][0]'}}, {'input_number': 0, 'stream_number': 1, 'stream_type': 'audio', 'language': None, 'default': True, 'fps': 44100, 'bitrate': 32, 'metadata': {'Metadata': '', 'handler_name': 'SoundHandler', 'vendor_id': '[0][0][0][0]'}}], 'input_number': 0}], 'duration': 12.95, 'bitrate': 1118, 'start': 0.0, 'default_video_input_number': 0, 'default_video_stream_number': 0, 'video_codec_name': 'h264', 'video_profile': '(High)', 'video_size': [576, 1024], 'video_bitrate': 1076, 'video_fps': 59.63, 'default_audio_input_number': 0, 'default_audio_stream_number': 1, 'audio_fps': 44100, 'audio_bitrate': 32, 'video_duration': 12.95, 'video_n_frames': 772}\n",
            "/usr/local/lib/python3.11/dist-packages/imageio_ffmpeg/binaries/ffmpeg-linux-x86_64-v7.0.2 -i /root/.cache/huggingface/hub/datasets--qubvel-hf--assets/snapshots/da3d6849ff7f73270abee0bcf01339a902c8d9a8/rt_pose_break_dance_v1.mp4 -loglevel error -f image2pipe -vf scale=576:1024 -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 772/772 [00:48<00:00, 16.04it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save annotated frames as video with the same audio from clip\n",
        "annotated_clip = moviepy.ImageSequenceClip(annotated_frames, fps=clip.fps)\n",
        "annotated_clip.audio = clip.audio\n",
        "\n",
        "dst_path = \"saved_video.mp4\"\n",
        "annotated_clip.write_videofile(dst_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0QKIkKvWiR4",
        "outputId": "5b8f5934-a5b8-4a93-eb83-c5958152e830"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Building video saved_video.mp4.\n",
            "MoviePy - Writing audio in saved_videoTEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing video saved_video.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done !\n",
            "MoviePy - video ready saved_video.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment next line to show annotated clip\n",
        "# show_clip(dst_path)"
      ],
      "metadata": {
        "id": "XxLCbDjsWkaC"
      },
      "execution_count": 40,
      "outputs": []
    }
  ]
}