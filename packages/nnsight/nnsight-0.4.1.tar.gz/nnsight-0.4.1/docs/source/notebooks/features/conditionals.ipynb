{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Interventions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interventions can also be made conditional. \n",
    "\n",
    "Inside the tracing context we can specify a new - conditional - context. This context will only execute the interventions within it if the condition is met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/nnsight_local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/homebrew/anaconda3/envs/nnsight_local/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Integer  tensor([5])  is Odd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from nnsight import LanguageModel\n",
    "\n",
    "model = LanguageModel('openai-community/gpt2', device_map='auto')\n",
    "\n",
    "with model.trace(\"The Eiffel Tower is in the city of\") as tracer:\n",
    "\n",
    "  rand_int = torch.randint(low=-10, high=10, size=(1,))\n",
    "\n",
    "  with tracer.cond(rand_int % 2 == 0):\n",
    "    tracer.log(\"Random Integer \", rand_int, \" is Even\")\n",
    "\n",
    "  with tracer.cond(rand_int % 2 == 1):\n",
    "    tracer.log(\"Random Integer \", rand_int, \" is Odd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above, we have two conditional contexts with mutually exclusive conditions, just like a usual `If`-`Else` statement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditional contexts can also be nested, if we want our interventions to depend on more than one condition at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rand Int  8  is Positive and Even\n"
     ]
    }
   ],
   "source": [
    "with model.trace(\"The Eiffel Tower is in the city of\") as tracer:\n",
    "\n",
    "  non_rand_int = 8\n",
    "  \n",
    "  with tracer.cond(non_rand_int > 0):\n",
    "    with tracer.cond(non_rand_int % 2 == 0):\n",
    "      tracer.log(\"Rand Int \", non_rand_int, \" is Positive and Even\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnsight_local",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
