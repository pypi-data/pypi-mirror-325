Metadata-Version: 2.2
Name: torchserve-nightly
Version: 2025.2.5
Summary: TorchServe is a tool for serving neural net models for inference
Home-page: https://github.com/pytorch/serve.git
Author: PyTorch Serving team
Author-email: noreply@noreply.com
License: Apache License Version 2.0
Keywords: TorchServe PyTorch Serving Deep Learning Inference AI
Description-Content-Type: text/x-rst
License-File: LICENSE
Requires-Dist: Pillow
Requires-Dist: psutil
Requires-Dist: packaging
Requires-Dist: wheel
Provides-Extra: onnx
Requires-Dist: numpy; extra == "onnx"
Requires-Dist: onnx; extra == "onnx"
Requires-Dist: onnx-runtime; extra == "onnx"
Provides-Extra: ipex
Requires-Dist: intel_extension_for_pytorch; extra == "ipex"
Dynamic: author
Dynamic: author-email
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: keywords
Dynamic: license
Dynamic: provides-extra
Dynamic: requires-dist
Dynamic: summary

Project Description
===================

TorchServe is a flexible and easy to use tool for
serving `PyTorch <http://pytorch.org/>`__ models in production.

Use the TorchServe CLI, or the pre-configured Docker images, to start a
service that sets up HTTP endpoints to handle model inference requests.

Installation
------------

Full installation instructions are in the project repo: https://github.com/pytorch/serve/blob/master/README.md


Source code
-----------

You can check the latest source code as follows:

::

    git clone https://github.com/pytorch/serve.git

Citation
--------

If you use torchserve in a publication or project, please cite torchserve:
https://github.com/pytorch/serve
