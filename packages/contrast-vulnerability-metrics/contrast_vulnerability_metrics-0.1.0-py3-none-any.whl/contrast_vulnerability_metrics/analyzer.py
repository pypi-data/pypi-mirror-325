"""
Core analyzer class for processing vulnerability data from the Contrast Security API.
"""

import asyncio
import logging
from datetime import datetime
from typing import List, Dict, Optional, Any, Type, AsyncIterator
from statistics import mean, median

import httpx
from tqdm.asyncio import tqdm

from .models import (
    Severity,
    VulnerabilityListResponse,
    VulnerabilityDetailResponse,
    VulnerabilityMetrics,
)
from .exceptions import ContrastAPIError
from .resilient import EnhancedAsyncClient, TimeoutConfig, APIRateLimiter

logger = logging.getLogger(__name__)


class VulnerabilityAnalyzer:
    """Analyzes vulnerability metrics from the Contrast Security API"""

    def __init__(
        self,
        base_url: str,
        org_uuid: str,
        api_key: str,
        auth: str,
        batch_size: int = 25,
        max_concurrent: int = 10,
        use_closed_time: bool = True,
        verbose: bool = False,
        start_date: Optional[datetime] = None,
        end_date: Optional[datetime] = None,
    ) -> None:
        self.base_url = base_url.rstrip("/")
        self.org_uuid = org_uuid
        self.batch_size = batch_size
        self.use_closed_time = use_closed_time
        self.verbose = verbose
        self.start_date = start_date
        self.end_date = end_date or datetime.now()
        self.headers = {
            "accept": "application/json",
            "content-type": "application/json",
            "API-Key": api_key,
            "Authorization": auth,
        }

        # Enhanced client configuration
        timeout_config = TimeoutConfig(
            connect_timeout=10.0,
            read_timeout=30.0,
            write_timeout=10.0,
            pool_timeout=10.0,
        )

        rate_limiter = APIRateLimiter(requests_per_second=10.0)

        self.client = EnhancedAsyncClient(
            timeout_config=timeout_config,
            rate_limiter=rate_limiter,
            headers=self.headers,
            follow_redirects=True,
            limits=httpx.Limits(
                max_keepalive_connections=max_concurrent, max_connections=max_concurrent
            ),
        )

        self.semaphore = asyncio.Semaphore(max_concurrent)
        logger.debug("Initialized VulnerabilityAnalyzer")

    async def __aenter__(self) -> "VulnerabilityAnalyzer":
        return self

    async def __aexit__(
        self,
        exc_type: Optional[Type[BaseException]],
        exc_val: Optional[BaseException],
        exc_tb: Optional[Any],
    ) -> None:
        await self.client.aclose()

    async def get_total_vulnerabilities(self) -> int:
        """Get the total number of vulnerabilities for pagination planning"""
        try:
            url = f"{self.base_url}/api/ng/organizations/{self.org_uuid}/orgtraces/ui"
            params: Dict[str, Any] = {"expand": "skip_links", "offset": 0, "limit": 1}
            data: Dict[str, Any] = {
                "quickFilter": "ALL",
                "severities": [
                    sev.value
                    for sev in [Severity.CRITICAL, Severity.HIGH, Severity.MEDIUM]
                ],
                # "licensedOnly": True,
                "status": ["Remediated", "Fixed"],
            }

            async with self.semaphore:
                response = await self.client.post(url, params=params, json=data)
                response.raise_for_status()
                response_data: VulnerabilityListResponse = response.json()
                return response_data.get("count", 0)
        except Exception as e:
            logger.error(f"Error getting total vulnerability count: {e}")
            raise

    async def get_vulnerabilities_page(
        self, offset: int = 0, limit: int = 25
    ) -> VulnerabilityListResponse:
        """Fetch a page of vulnerabilities from the API"""
        url = f"{self.base_url}/api/ng/organizations/{self.org_uuid}/orgtraces/ui"
        params: Dict[str, Any] = {
            "expand": "skip_links",
            "offset": offset,
            "limit": limit,
        }
        data: Dict[str, Any] = {
            "quickFilter": "ALL",
            "severities": [
                sev.value for sev in [Severity.CRITICAL, Severity.HIGH, Severity.MEDIUM]
            ],
            # "licensedOnly": True,
            "status": ["Remediated", "Fixed"],
        }

        response = None
        async with self.semaphore:
            try:
                response = await self.client.post(url, params=params, json=data)
                response.raise_for_status()
                return response.json()
            except httpx.HTTPError as e:
                logger.error(f"HTTP error occurred: {e}")
                raise ContrastAPIError(str(e), response)
            
    async def get_vulnerability_detail(
        self, vuln_uuid: str
    ) -> VulnerabilityDetailResponse:
        """Fetch detailed vulnerability data from the API"""
        url = f"{self.base_url}/api/ng/{self.org_uuid}/orgtraces/filter/{vuln_uuid}"
        params = {"expand": "skip_links"}

        response = None
        async with self.semaphore:
            try:
                response = await self.client.get(url, params=params)
                response.raise_for_status()
                return response.json()
            except httpx.HTTPError as e:
                logger.error(f"HTTP error occurred: {e}")
                raise ContrastAPIError(str(e), response)

    def calculate_time_to_remediate(
        self, first_time: int, last_time: int, closed_time: Optional[int]
    ) -> tuple[int, Optional[int]]:
        """Calculate time to last seen and time to remediation in days"""
        first_dt = datetime.fromtimestamp(first_time / 1000)
        last_dt = datetime.fromtimestamp(last_time / 1000)
        time_to_last = (last_dt - first_dt).days

        time_to_remediate = None
        if closed_time:
            closed_dt = datetime.fromtimestamp(closed_time / 1000)
            time_to_remediate = (closed_dt - first_dt).days

        return time_to_last, time_to_remediate

    def is_within_time_range(self, metric_date: datetime) -> bool:
        """Check if a date falls within the specified time range"""
        if self.start_date and metric_date < self.start_date:
            return False
        if metric_date > self.end_date:
            return False
        return True

    async def process_vulnerability_details(
        self, vuln_uuids: List[str]
    ) -> AsyncIterator[VulnerabilityMetrics]:
        """Process vulnerability details concurrently"""
        async def fetch_and_process(uuid: str) -> Optional[VulnerabilityMetrics]:
            try:
                response = await self.get_vulnerability_detail(uuid)
                trace = response["trace"]
                
                # Skip if no closed_time
                closed_time = trace.get("closed_time")
                if not closed_time:
                    return None

                first_time = trace["first_time_seen"]
                last_time = trace["last_time_seen"]
                
                # Convert timestamps to datetime objects for filtering
                # Guard against None with explicit check
                if closed_time:
                    closed_dt = datetime.fromtimestamp(closed_time / 1000)
                else:
                    return None
                
                # Skip if not within time range
                if not self.is_within_time_range(closed_dt):
                    return None
                
                time_to_last, time_to_remediate = self.calculate_time_to_remediate(
                    first_time, last_time, closed_time
                )
                
                return VulnerabilityMetrics(
                    uuid=trace["uuid"],
                    severity=trace["severity"],
                    first_time_seen=datetime.fromtimestamp(first_time / 1000),
                    last_time_seen=datetime.fromtimestamp(last_time / 1000),
                    closed_time=closed_dt,
                    time_to_last_seen=time_to_last,
                    time_to_remediation=time_to_remediate
                )
            except Exception as e:
                logger.error(f"Error processing vulnerability {uuid}: {e}")
                return None

        # Process vulnerabilities concurrently in batches
        batch_size = self.semaphore._value
        for i in range(0, len(vuln_uuids), batch_size):
            batch = vuln_uuids[i : i + batch_size]
            tasks = [fetch_and_process(uuid) for uuid in batch]
            results = await asyncio.gather(*tasks)

            for result in results:
                if result is not None:
                    yield result

    async def analyze_vulnerabilities(
        self,
    ) -> tuple[List[VulnerabilityMetrics], Dict[str, Any]]:
        """Analyze vulnerability metrics across all vulnerabilities"""
        metrics: List[VulnerabilityMetrics] = []
        vuln_uuids: List[str] = []

        # Get total count first
        total_vulns = await self.get_total_vulnerabilities()
        logger.info(f"Found {total_vulns} total vulnerabilities to process")

        # Fetch all vulnerability UUIDs
        with tqdm(
            total=total_vulns, desc="Fetching vulnerabilities", disable=not self.verbose
        ) as pbar:
            for offset in range(0, total_vulns, self.batch_size):
                response = await self.get_vulnerabilities_page(offset, self.batch_size)
                for item in response["items"]:
                    vuln = item["vulnerability"]
                    vuln_uuids.append(vuln["uuid"])
                pbar.update(len(response["items"]))

        # Process vulnerability details
        with tqdm(
            total=len(vuln_uuids), desc="Processing details", disable=not self.verbose
        ) as pbar:
            async for metric in self.process_vulnerability_details(vuln_uuids):
                metrics.append(metric)
                pbar.update(1)

        # Calculate summary statistics
        summary = self.calculate_summary_statistics(metrics)

        return metrics, summary

    def calculate_summary_statistics(
        self, metrics: List[VulnerabilityMetrics]
    ) -> Dict[str, Any]:
        """Calculate summary statistics for vulnerability metrics"""

        def calc_stats(values: List[int]) -> Dict[str, Any]:
            if not values:
                return {"avg": 0, "median": 0, "count": 0}
            return {
                "avg": round(mean(values)),
                "median": round(median(values)),
                "count": len(values),
            }

        # Group by severity
        severity_groups: Dict[str, List[int]] = {
            "CRITICAL": [],
            "HIGH": [],
            "MEDIUM": [],
        }

        time_field = (
            "time_to_remediation" if self.use_closed_time else "time_to_last_seen"
        )

        for metric in metrics:
            time_value = metric[time_field]
            if time_value is not None:
                # Normalize severity to uppercase
                severity = metric["severity"].upper()
                if severity in severity_groups:
                    severity_groups[severity].append(time_value)
                else:
                    logger.warning(f"Unexpected severity level: {metric['severity']}")

        # Calculate statistics for each severity
        stats = {
            severity: calc_stats(times) for severity, times in severity_groups.items()
        }

        # Calculate overall statistics
        all_times = [time for group in severity_groups.values() for time in group]
        stats["OVERALL"] = calc_stats(all_times)

        return stats
