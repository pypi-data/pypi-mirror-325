Metadata-Version: 2.1
Name: pydantic-ai-langfuse
Version: 0.1.2
Summary: Langfuse integration for pydantic-ai
License: MIT
Author: Gabriele Ghisleni
Author-email: gabriele.ghisleni01@gmail.com
Requires-Python: >=3.10,<4.0
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Dist: langfuse[openai] (>=2.58.2,<3.0.0)
Requires-Dist: pydantic-ai-slim[openai] (>=0.0.21,<0.0.22)
Description-Content-Type: text/markdown

# pydantic-ai-langfuse

pydantic-ai-langfuse extends [pydantic-ai-slim](https://pypi.org/project/pydantic-ai-slim/) to integrate Langfuse tracking into your OpenAI model interactions. By incorporating our Langfuse OpenAI model settings, you can easily label, track, and filter your generations using enriched metadata.

## Installation

Ensure you have the required dependencies installed:

```bash
pip install pydantic-ai-langfuse
```

## Environment Setup

Before running your model, you need to set up the following environment variables:

- `OPENAI_API_KEY`: Your OpenAI API key.
- `LANGFUSE_PUBLIC_KEY`: Your Langfuse public key.
- `LANGFUSE_SECRET_KEY`: Your Langfuse secret key.
- `LANGFUSE_HOST`: Your Langfuse host endpoint.

## Quickstart

Below is a complete Python example showing how to set up and use the LangfuseOpenAIModel with extra model settings. This example uses the synchronous `run_sync` method with basic error handling and retries built in.

```python
import os

from langfuse.openai import AsyncOpenAI
from pydantic_ai import Agent

from pydantic_ai_langfuse import LangfuseOpenAIModel

for var in [
    "OPENAI_API_KEY",
    "LANGFUSE_PUBLIC_KEY",
    "LANGFUSE_SECRET_KEY",
    "LANGFUSE_HOST",
]:
    if var not in os.environ:
        raise OSError(f"Missing env variable: {var}")

weather_agent = Agent(
    model=LangfuseOpenAIModel("gpt-4o", openai_client=AsyncOpenAI()),
    system_prompt="Be concise: reply with one sentence.",
    retries=2,
)

result = weather_agent.run_sync(
    "What the weather like in Medolago BG?",
    model_settings={
        "name": "weather_query",
        "metadata": {"location": "medolago", "query_type": "weather"},
        "session_id": "testoneditest",
        "user_id": "user123",
        "tags": ["weather", "italy", "query"],
    },
)

print("Response:", result.data)

```

