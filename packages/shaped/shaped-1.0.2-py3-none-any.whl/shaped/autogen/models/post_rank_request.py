# coding: utf-8

"""
    Shaped API

    Welcome to Shaped's API reference docs. These provide a detailed view of the endpoints and CLI commands that Shaped provides and brief explanations of how they should be used.   Shaped's API is composed of 3 components:   1. **Dataset** - used to provision and manage 'Shaped Datasets', which are persisted     data views of external data. Shaped Datasets can be created from any of our     'Shaped connectors' (e.g. S3, Segment, Snowflake, etc.) and support both batch     ingestion (up to a 15min delay) and stream ingestion (up to a 30 second     delay) depending on the specific connector used. Shaped datasets can also be     created from local files, which is particularly useful for getting started     with a snapshot of data.    2. **Model Management** - used to provision and manage 'Shaped Models', which     represent a system of data pipelines, training and serving infrastructure for     your ranking use-case.    3. **Model Inference** - a high performance API that's used to make     user-understanding requests or ranking inferences to your 'Shaped Models'. For     example, the 'rank' endpoint can be used to determine for a given user id     query, what is the content that is most engaging to that user.    The recommended workflow to interact with the Shaped API is as follows:   1. First create 'Shaped Datasets' to sync over data that your Shaped     understanding models will need. The models at the minimum need interaction     data to understand behavior of your users, so start with that and add your item     and user catalog data later.   2. Then create 'Shaped Models' that use your created 'Shaped Datasets' as     input. Your Shaped Model will will start streaming, processing and training     from your connected data immediately. After a few hours your model will have     tuned all parameters based on your data and will deploy an active model.   3. You can now use the 'Model Inference' endpoints to make real-time     inferences to your model based on your use-case. 

    The version of the OpenAPI document: 1.0.1
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictStr
from typing import Any, ClassVar, Dict, List, Optional
from shaped.autogen.models.inference_config import InferenceConfig
from shaped.autogen.models.interaction import Interaction
from typing import Optional, Set
from typing_extensions import Self

class PostRankRequest(BaseModel):
    """
    PostRankRequest
    """ # noqa: E501
    user_id: Optional[StrictStr] = Field(default=None, description="The user id to personalize the ranking to.")
    item_ids: Optional[List[StrictStr]] = Field(default=None, description="A list of candidate items to rank. If not provided then we will use our own retrieval algorithms to fetch relevant items from the input queries. ")
    interactions: Optional[List[Interaction]] = Field(default=None, description="A list of historically ordered positive interactions for the current user's session. These interactions are appended onto the interactions found in Shaped's internal interaction store before ranking. ")
    filter_predicate: Optional[StrictStr] = Field(default=None, description="A SQL where query that can be used to filter out candidate items.")
    user_features: Optional[Dict[str, Any]] = Field(default=None, description="Instead of providing a user id, you may provide the user features directly. This can be helpful when the user features change in real-time and need to be ranked immediately with the updated features. ")
    item_features: Optional[Dict[str, Any]] = Field(default=None, description="Instead of providing candidate item ids, you maybe provide their item features directly. This allows new items to be ranked in real-time, even if they haven't been ingested by Shaped yet. ")
    text_query: Optional[StrictStr] = Field(default=None, description="A free text text query to filter retrieved items using our underlying hybrid bm25 and semantic search engine on text indexed fields. Note that text_index: True needs to be set when creating a model to enable the this feature. ")
    flush_paginations: Optional[StrictBool] = Field(default=False, description="Clears the pagination store for the given input user. This is useful if you want to implement paginations on client side or if you want to start the rankings again, e.g. on a page refresh. ")
    return_metadata: Optional[StrictBool] = Field(default=False, description="If true, return the corresponding metadata for the ranked items.")
    config: Optional[InferenceConfig] = None
    __properties: ClassVar[List[str]] = ["user_id", "item_ids", "interactions", "filter_predicate", "user_features", "item_features", "text_query", "flush_paginations", "return_metadata", "config"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of PostRankRequest from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of each item in interactions (list)
        _items = []
        if self.interactions:
            for _item_interactions in self.interactions:
                if _item_interactions:
                    _items.append(_item_interactions.to_dict())
            _dict['interactions'] = _items
        # override the default output from pydantic by calling `to_dict()` of config
        if self.config:
            _dict['config'] = self.config.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of PostRankRequest from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "user_id": obj.get("user_id"),
            "item_ids": obj.get("item_ids"),
            "interactions": [Interaction.from_dict(_item) for _item in obj["interactions"]] if obj.get("interactions") is not None else None,
            "filter_predicate": obj.get("filter_predicate"),
            "user_features": obj.get("user_features"),
            "item_features": obj.get("item_features"),
            "text_query": obj.get("text_query"),
            "flush_paginations": obj.get("flush_paginations") if obj.get("flush_paginations") is not None else False,
            "return_metadata": obj.get("return_metadata") if obj.get("return_metadata") is not None else False,
            "config": InferenceConfig.from_dict(obj["config"]) if obj.get("config") is not None else None
        })
        return _obj


