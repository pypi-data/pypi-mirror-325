# coding: utf-8

"""
    Shaped API

    Welcome to Shaped's API reference docs. These provide a detailed view of the endpoints and CLI commands that Shaped provides and brief explanations of how they should be used.   Shaped's API is composed of 3 components:   1. **Dataset** - used to provision and manage 'Shaped Datasets', which are persisted     data views of external data. Shaped Datasets can be created from any of our     'Shaped connectors' (e.g. S3, Segment, Snowflake, etc.) and support both batch     ingestion (up to a 15min delay) and stream ingestion (up to a 30 second     delay) depending on the specific connector used. Shaped datasets can also be     created from local files, which is particularly useful for getting started     with a snapshot of data.    2. **Model Management** - used to provision and manage 'Shaped Models', which     represent a system of data pipelines, training and serving infrastructure for     your ranking use-case.    3. **Model Inference** - a high performance API that's used to make     user-understanding requests or ranking inferences to your 'Shaped Models'. For     example, the 'rank' endpoint can be used to determine for a given user id     query, what is the content that is most engaging to that user.    The recommended workflow to interact with the Shaped API is as follows:   1. First create 'Shaped Datasets' to sync over data that your Shaped     understanding models will need. The models at the minimum need interaction     data to understand behavior of your users, so start with that and add your item     and user catalog data later.   2. Then create 'Shaped Models' that use your created 'Shaped Datasets' as     input. Your Shaped Model will will start streaming, processing and training     from your connected data immediately. After a few hours your model will have     tuned all parameters based on your data and will deploy an active model.   3. You can now use the 'Model Inference' endpoints to make real-time     inferences to your model based on your use-case. 

    The version of the OpenAPI document: 1.0.1
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictFloat, StrictInt, StrictStr
from typing import Any, ClassVar, Dict, List, Optional, Union
from shaped.autogen.models.retriever_top_k_override import RetrieverTopKOverride
from typing import Optional, Set
from typing_extensions import Self

class InferenceConfig(BaseModel):
    """
    This object defines global configurations for all inference endpoints. It can be set at model definition time, in which case it will be used as the default for all inference requests. It can also be set at inference time, in which case it will override the model's default configuration. 
    """ # noqa: E501
    exploration_factor: Optional[Union[StrictFloat, StrictInt]] = Field(default=None, description="Exploration factor defines how much to explore newer, low interaction items relative to the highest scored relevant items. Higher values are more likely to return items from our cold-start item pools (i.e. new items with less interactions), lower values are more likely to return items with more interactions that are highly relevant. ")
    diversity_factor: Optional[Union[StrictFloat, StrictInt]] = Field(default=None, description="Diversity factor defines how much to trade-off relevance and attribute diversity when re-ranking results. We achieve this with a Maximal Marginal Relevance algorithm that chooses the most diverse item out of a set of maximally relevant items at each rank. Higher diversity factor means favor more diverse results over more relevant ones. ")
    diversity_attributes: Optional[List[StrictStr]] = Field(default=None, description="The list of item attributes to calculate diversity with. For example, say your content has the following attributes: price, brand, category, timestamp. You may only want to diversify around brand and category, but disregard price and timestamp. In this case, just set diversity_attributes to: [\"brand\", \"category\"]. ")
    retrieval_k: Optional[Union[StrictFloat, StrictInt]] = Field(default=None, description="Defines how many candidate items to pull from retrieval stage (i.e. the aggregate of all retrievers). Defaults to 300. ")
    retriever_k_override: Optional[RetrieverTopKOverride] = None
    limit: Optional[StrictInt] = Field(default=None, description="The number of items to return.")
    __properties: ClassVar[List[str]] = ["exploration_factor", "diversity_factor", "diversity_attributes", "retrieval_k", "retriever_k_override", "limit"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of InferenceConfig from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of retriever_k_override
        if self.retriever_k_override:
            _dict['retriever_k_override'] = self.retriever_k_override.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of InferenceConfig from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "exploration_factor": obj.get("exploration_factor"),
            "diversity_factor": obj.get("diversity_factor"),
            "diversity_attributes": obj.get("diversity_attributes"),
            "retrieval_k": obj.get("retrieval_k"),
            "retriever_k_override": RetrieverTopKOverride.from_dict(obj["retriever_k_override"]) if obj.get("retriever_k_override") is not None else None,
            "limit": obj.get("limit")
        })
        return _obj


