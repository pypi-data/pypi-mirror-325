# coding: utf-8

"""
    Shaped API

    Welcome to Shaped's API reference docs. These provide a detailed view of the endpoints and CLI commands that Shaped provides and brief explanations of how they should be used.   Shaped's API is composed of 3 components:   1. **Dataset** - used to provision and manage 'Shaped Datasets', which are persisted     data views of external data. Shaped Datasets can be created from any of our     'Shaped connectors' (e.g. S3, Segment, Snowflake, etc.) and support both batch     ingestion (up to a 15min delay) and stream ingestion (up to a 30 second     delay) depending on the specific connector used. Shaped datasets can also be     created from local files, which is particularly useful for getting started     with a snapshot of data.    2. **Model Management** - used to provision and manage 'Shaped Models', which     represent a system of data pipelines, training and serving infrastructure for     your ranking use-case.    3. **Model Inference** - a high performance API that's used to make     user-understanding requests or ranking inferences to your 'Shaped Models'. For     example, the 'rank' endpoint can be used to determine for a given user id     query, what is the content that is most engaging to that user.    The recommended workflow to interact with the Shaped API is as follows:   1. First create 'Shaped Datasets' to sync over data that your Shaped     understanding models will need. The models at the minimum need interaction     data to understand behavior of your users, so start with that and add your item     and user catalog data later.   2. Then create 'Shaped Models' that use your created 'Shaped Datasets' as     input. Your Shaped Model will will start streaming, processing and training     from your connected data immediately. After a few hours your model will have     tuned all parameters based on your data and will deploy an active model.   3. You can now use the 'Model Inference' endpoints to make real-time     inferences to your model based on your use-case. 

    The version of the OpenAPI document: 1.0.1
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictStr
from typing import Any, ClassVar, Dict, List, Optional
from typing import Optional, Set
from typing_extensions import Self

class ViewModelResponse(BaseModel):
    """
    ViewModelResponse
    """ # noqa: E501
    model_name: Optional[StrictStr] = None
    model_uri: Optional[StrictStr] = None
    fetch: Optional[StrictStr] = None
    var_schema: Optional[StrictStr] = Field(default=None, alias="schema")
    created_at: Optional[StrictStr] = None
    trained_at: Optional[StrictStr] = None
    status: Optional[StrictStr] = Field(default=None, description="Status takes the following values depending on which stage of the model creation pipeline it's at:   1. SCHEDULING -- your model is awaiting resources to be provisioned and used to fetch, train, and deploy your model.   2. FETCHING -- your historic data is being fetched.   3. TUNING -- your recommendation system configuration and models are being optimized for your dataset.   4. TRAINING -- your model is being trained on your historic dataset.   5. DEPLOYING -- your model is being deployed to your custom real-time endpoint.   6. ACTIVE -- your model is active and ready for rank requests.   7. ERROR -- there was an error at some point when creating your model. ")
    __properties: ClassVar[List[str]] = ["model_name", "model_uri", "fetch", "schema", "created_at", "trained_at", "status"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of ViewModelResponse from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of ViewModelResponse from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "model_name": obj.get("model_name"),
            "model_uri": obj.get("model_uri"),
            "fetch": obj.get("fetch"),
            "schema": obj.get("schema"),
            "created_at": obj.get("created_at"),
            "trained_at": obj.get("trained_at"),
            "status": obj.get("status")
        })
        return _obj


